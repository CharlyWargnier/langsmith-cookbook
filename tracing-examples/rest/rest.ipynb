{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ddd44f6-80a3-4c3c-b467-1a2a2cc05d62",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tracing via the REST API\n",
    "\n",
    "It's likely that your production LLM application is written in a language other than Python or JavaScript. In this case, you can use the REST API to log runs and take advantage of LangSmith's tracing and monitoring functionality. Doing so can be as simple as a POST request to the langsmith API. Specifically, to log runs you must:\n",
    "\n",
    "- Submit a POST request to \"https://api.smith.langchain.com/runs\"\n",
    "- JSON body of the request must have a name, run_type, inputs, and any other desired information.\n",
    "- An \"x-api-key\" header must be provided to authenticate, using a valid API key created in the LangSmith app\n",
    "\n",
    "\n",
    "## Example\n",
    "\n",
    "Below is a minimal example of how to create a run using the REST API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5aff79e-8f03-4f3b-a347-032ce74bcd6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "_LANGSMITH_API_KEY=os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "\n",
    "res = requests.post(\n",
    "    \"https://api.smith.langchain.com/runs\",\n",
    "    json={\n",
    "        \"name\": \"MyRun\",\n",
    "        \"run_type\": \"chain\",\n",
    "        \"inputs\": {\"text\": \"Foo\"},\n",
    "    },\n",
    "    headers={\n",
    "        \"x-api-key\": _LANGSMITH_API_KEY\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1521e322-8585-4d3a-acea-65eaa1a5334f",
   "metadata": {},
   "source": [
    "This will create a barebones \"chain\" run with the name \"MyRun\" and json inputs of {\"text\": \"Foo\"} that looks something like the following:\n",
    "\n",
    "<a href=\"https://smith.langchain.com/public/956e641a-4f1a-492d-9a67-3990f3fdba3e/r\"><img src=\"./img/minimal.png\" alt=\"minimal trace example\" style=\"width:75%\"></a>\n",
    "\n",
    "Not much information is included, since we haven't added outputs, tags, or metadata yet. It is also marked as \"pending\" since we haven't added an end time yet.\n",
    "\n",
    "In addition to the name, run_type, and inputs, you can also provide additional information. Below is an example of the supported schema:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"name\": \"string\",\n",
    "  \"inputs\": {},\n",
    "  \"run_type\": \"string\",\n",
    "  \"start_time\": \"2019-08-24T14:15:22Z\", # UTC timestamp in ISO format\n",
    "  \"end_time\": \"2019-08-24T14:15:22Z\", # UTC timestamp in ISO format\n",
    "  \"extra\": {},\n",
    "  \"error\": \"string\",\n",
    "  \"execution_order\": 1,\n",
    "  \"outputs\": {},\n",
    "  \"parent_run_id\": \"f8faf8c1-9778-49a4-9004-628cdb0047e5\",\n",
    "  \"events\": [\n",
    "    {}\n",
    "  ],\n",
    "  \"tags\": [\n",
    "    \"string\"\n",
    "  ],\n",
    "  \"id\": \"497f6eca-6276-4993-bfeb-53cbbbba6f08\",\n",
    "  \"session_id\": \"1ffd059c-17ea-40a8-8aef-70fd0307db82\",\n",
    "  \"session_name\": \"string\", # This is the name of the PROJECT. \"default\" if not specified. Sessions are the old name for projects.\n",
    "  \"reference_example_id\": \"9fb06aaa-105f-4c87-845f-47d62ffd7ee6\"\n",
    "}\n",
    "```\n",
    "\n",
    "This can also be found in the [API documentation](https://web.smith.langchain.com/redoc#tag/run/operation/create_run_runs_post).\n",
    "\n",
    "Lets look at a more complex chain example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b41f863-ba8e-41e5-908c-f74f770e00b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import datetime\n",
    "import platform\n",
    "\n",
    "start = datetime.datetime.utcnow() - datetime.timedelta(seconds=10)\n",
    "end = datetime.datetime.utcnow()\n",
    "res = requests.post(\n",
    "    \"https://api.smith.langchain.com/runs\",\n",
    "    json={\n",
    "        \"name\": \"ParentRun\",\n",
    "        \"run_type\": \"chain\",\n",
    "        \"inputs\": {\"text\": \"Foo\"},\n",
    "        \"outputs\": {\"generated\": \"Bar\"},\n",
    "        \"start_time\": start.isoformat(),\n",
    "        \"end_time\": end.isoformat(),\n",
    "        \"session_name\": \"My REST Project\",\n",
    "        \"tags\": [\"langsmith\", \"rest\", \"my-example\"],\n",
    "        \"events\": [\n",
    "            {\"event_name\": \"retry\", \"time\": start.isoformat()},\n",
    "            {\"event_name\": \"new_token\", \"value\": \"foo\"},\n",
    "        ],\n",
    "        \"extra\": {\n",
    "            \"metadata\": {\n",
    "                \"my_key\": \"My value\"\n",
    "            },\n",
    "            \"runtime\": {\n",
    "                \"platform\": platform.platform(),\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    headers={\n",
    "        \"x-api-key\": _LANGSMITH_API_KEY\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6cdc54-9604-47f5-886c-8c0dfc10ef1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Below is an example screenshot of what the logged trace above looks like. The new run now has inputs and outputs, a latency calculation, tags, and a status indicator.\n",
    "\n",
    "<a href=\"https://smith.langchain.com/public/69ca776a-60e4-4c4c-8b59-c8731e7f52f0/r\"><img src=\"./img/populated.png\" alt=\"populated trace example\" style=\"width:75%\"></a>\n",
    "\n",
    "To see the logged metadata and other runtime information you saved in the trace above, you can navigate to the \"metadata\" tab:\n",
    "    \n",
    "<a href=\"https://smith.langchain.com/public/69ca776a-60e4-4c4c-8b59-c8731e7f52f0/r?tab=2\"><img src=\"./img/populated_metadata.png\" alt=\"trace metadata\" style=\"width:75%\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f9e644-bf1a-4b5d-802b-6eae3b55196c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logging LLM Runs\n",
    "\n",
    "The chain runs logged above are versatile and can be used to represent just about any function in your application. To get even more out of LangSmith, you'll want to also log your language model runs.\n",
    "\n",
    "Runs with the `run_type` of \"llm\" get some special treatment. They allow us to:\n",
    "\n",
    "- Help track token usage\n",
    "- Render \"prettier\" chat message formats for better readability.\n",
    "\n",
    "This is the case both for chat models and for regular \"completion\" LLMs.\n",
    "\n",
    "The easiest way to log LLM runs to LangSmith is by using OpenAI's llm message schema in the inputs and outputs.\n",
    "\n",
    "We will show examples below.\n",
    "\n",
    "#### Logging LLM Chat Messages\n",
    "\n",
    "To log messages in the \"chat\" model format (role and message dictionaries), LangSmith expects the following format:\n",
    "\n",
    "- Provide `messages: [{\"role\": string, \"content\": string}]` as a key-value pair in the inputs\n",
    "- Provide `choices: [{\"message\": {\"role\": string, \"content\": string}]` as a key-value pair in the outputs.\n",
    "\n",
    "For function calling, you can also pass a `functions=[...]` key-value pair in the inputs, and include a `function_call: {\"name\": string, \"arguments\": {}}` key-value pair in the message choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e66e6-e819-4c5d-b24e-d5f5236be86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests.post(\n",
    "    \"https://api.smith.langchain.com/runs\",\n",
    "    json={\n",
    "        \"name\": \"MyChatModelRun\",\n",
    "        \"run_type\": \"llm\",\n",
    "        \"inputs\": {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in SF like?\"}],\n",
    "            # Optional\n",
    "            \"model\": \"text-davinci-003\", \n",
    "            \"functions\": [{\n",
    "              \"name\": \"get_current_weather\",\n",
    "              \"description\": \"Get the current weather in a given location\",\n",
    "              \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                  \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                  },\n",
    "                  \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                  }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "              }}],\n",
    "            # You can add other invocation paramers as k-v pairs\n",
    "            \"temperature\": 0.0,\n",
    "        },\n",
    "        \"outputs\": {\n",
    "              \"choices\": [\n",
    "                    {\n",
    "                      \"index\": 0,\n",
    "                      \"message\": {\n",
    "                        \"role\": \"assistant\",\n",
    "                        # Content is whatever string response the\n",
    "                        # model generates\n",
    "                        \"content\": None,\n",
    "                        # Function call is the function invocation and arguments\n",
    "                        # as a string\n",
    "                        \"function_call\": {\n",
    "                          \"name\": \"get_current_weather\",\n",
    "                          \"arguments\": \"{\\n\\\"location\\\": \\\"San Francisco, CA\\\"\\n}\"\n",
    "                        }\n",
    "                      },\n",
    "                      \"finish_reason\": \"function_call\"\n",
    "                    }\n",
    "                  ],\n",
    "        },\n",
    "        \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "    },\n",
    "    headers={\n",
    "        \"x-api-key\": _LANGSMITH_API_KEY\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0a3663-bedf-4416-b565-720bfa56c300",
   "metadata": {},
   "source": [
    "TODO: Add screenshot once in prod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8ca5d0-6beb-4882-b74b-e378b6839bf4",
   "metadata": {},
   "source": [
    "#### Logging \"Completions\" Models\n",
    "\n",
    "To log in the \"completions\" format (string in, string out), LangSmith expects the following format:\n",
    "- Name the run \"openai.Completion.create\" or \"openai.Completion.acreate\"\n",
    "- Provide `prompt: string` as a key-value pair in the inputs\n",
    "- Provide `choices: [{\"text\": string}]` key-value pair in the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67761b57-9c0c-441b-92b5-935b059bdaff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests.post(\n",
    "    \"https://dev.api.smith.langchain.com/runs\",\n",
    "    json={\n",
    "        \"name\": \"MyLLMRun\",\n",
    "        \"run_type\": \"llm\",\n",
    "        \"inputs\": {\n",
    "            \"prompt\": \"Hi there!\",\n",
    "            # Optional: model or engine name, and other invocation params\n",
    "            \"engine\": \"text-davinci-003\",\n",
    "            \"temperature\": 0.0\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            'choices': [\n",
    "                {\n",
    "                   'text': 'DEFG\\n\\nABCDFEG',\n",
    "                   'index': 0,\n",
    "                   'logprobs': None,\n",
    "                   'finish_reason': 'stop',\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "        \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        \n",
    "    },\n",
    "    headers={\n",
    "        \"x-api-key\": _LANGSMITH_API_KEY\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3b049-9192-4ff0-bb16-ecc527a91f7d",
   "metadata": {},
   "source": [
    "TODO: Add screenshot once in prod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492eb4ab-c5ef-457f-8733-caa0ea831e3a",
   "metadata": {},
   "source": [
    "## Updating Runs\n",
    "\n",
    "Once an end time has been assigned to a run, it is marked as finished and cannot be updated. Runs correspond to timespans with start and end times. For the most responsive web experience, it is recommended that you first post the inputs, tags, and other initial data to the run when a function or LLM method starts, then when it errs or succeeds, patch the outputs. Below is an example of how to do this. Note that in order to ensure that logging does not impact the execution time of your program, it is recommended to run it in a background thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c75223-bf93-4393-a419-633a5e240a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Optional\n",
    "\n",
    "_LANGSMITH_API_KEY=os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "_LANGSMITH_PROJECT=os.environ.get(\"LANGCHAIN_PROJECT\", \"My REST Project\")\n",
    "\n",
    "def post_run(data: dict, name: str, run_id: str) -> None:\n",
    "    requests.post(\n",
    "        \"https://api.smith.langchain.com/runs\",\n",
    "        json={\n",
    "            \"id\": run_id,\n",
    "            \"name\": name,\n",
    "            \"run_type\": \"chain\",\n",
    "            \"inputs\": data,\n",
    "            \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "            \"session_name\": _LANGSMITH_PROJECT,\n",
    "        },\n",
    "        headers={\n",
    "            \"x-api-key\": _LANGSMITH_API_KEY\n",
    "        }\n",
    "    )\n",
    "\n",
    "def patch_run(run_id, output: Optional[dict] = None, error: Optional[str] =None) -> None:\n",
    "    requests.patch(\n",
    "        f\"https://api.smith.langchain.com/runs/{run_id}\",\n",
    "        json={\n",
    "            \"error\": error,\n",
    "            \"outputs\": output,\n",
    "            \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "        },\n",
    "        headers={\n",
    "            \"x-api-key\": _LANGSMITH_API_KEY\n",
    "        }\n",
    "    )\n",
    "    \n",
    "def my_function(a, b):\n",
    "    run_id = str(uuid.uuid4())\n",
    "    post_run({\"a\": a, \"b\": b}, \"my_function\", run_id)\n",
    "    try:\n",
    "        result = a + b\n",
    "        patch_run(run_id, output={\"result\": result})\n",
    "    except Exception as e:\n",
    "        patch_run(run_id, error=str(e))\n",
    "        raise\n",
    "    return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b9d859-510b-4366-83a6-6ae590c3eda3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_function(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c808775-07e2-4a7b-af89-77ff034026d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    my_function(1, \"oops\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd688a7-e4c9-450e-943e-70f8f1ed45ca",
   "metadata": {},
   "source": [
    "## Nesting Runs\n",
    "\n",
    "The above examples work great for linear logs, but it's a lot easier to debug a complex chain if you nest them. There are currently two bits of complexity to do so. We plan to relax the execution order requirement at some point in the future:\n",
    "\n",
    "- You must include a `parent_run_id` in your JSON body.\n",
    "- You must track the `execution_order` of the child run for it to be rendered correctly in the trace.\n",
    "\n",
    "Below is an updated example of how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e3cb65-94be-404a-8bab-45c7bd573052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Optional\n",
    "\n",
    "_LANGSMITH_API_KEY=os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "_LANGSMITH_PROJECT=os.environ.get(\"LANGCHAIN_PROJECT\", \"My REST Project\")\n",
    "\n",
    "class RunLogger:\n",
    "    def __init__(self):\n",
    "        self._run_map = {}\n",
    "        self._parents = {}\n",
    "        \n",
    "    def _get_execution_order(self, run_id: str, parent_run_id: Optional[str] = None) -> int:\n",
    "        if parent_run_id:\n",
    "            self._parents[run_id] = parent_run_id\n",
    "            execution_order = self._run_map.get(parent_run_id, 0)\n",
    "            execution_order += 1\n",
    "            self._run_map[parent_run_id] = execution_order\n",
    "        else:\n",
    "            execution_order = 1\n",
    "        self._run_map[run_id] = execution_order\n",
    "        return execution_order\n",
    "\n",
    "    def _update_execution_order(self, run_id: str) -> None:\n",
    "        exec_order = self._run_map[run_id]\n",
    "        parent_run_id = self._parents.pop(run_id, None)\n",
    "        if parent_run_id:\n",
    "            self._run_map[parent_run_id] = max(exec_order, self._run_map[parent_run_id])\n",
    "        \n",
    "    def post_run(self, data: dict, name: str, run_id: str, parent_run_id: Optional[str] = None) -> None:\n",
    "        execution_order = self._get_execution_order(run_id, parent_run_id)\n",
    "        requests.post(\n",
    "            \"https://api.smith.langchain.com/runs\",\n",
    "            json={\n",
    "                \"id\": run_id,\n",
    "                \"name\": name,\n",
    "                \"run_type\": \"chain\",\n",
    "                \"parent_run_id\": parent_run_id,\n",
    "                \"execution_order\": execution_order,\n",
    "                \"inputs\": data,\n",
    "                \"start_time\": datetime.datetime.utcnow().isoformat(),\n",
    "                \"session_name\": _LANGSMITH_PROJECT,\n",
    "            },\n",
    "            headers={\n",
    "                \"x-api-key\": _LANGSMITH_API_KEY\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def patch_run(self, run_id: str, output: Optional[dict] = None, error: Optional[str] =None) -> None:\n",
    "        self._update_execution_order(run_id)\n",
    "        requests.patch(\n",
    "            f\"https://api.smith.langchain.com/runs/{run_id}\",\n",
    "            json={\n",
    "                \"error\": error,\n",
    "                \"outputs\": output,\n",
    "                \"end_time\": datetime.datetime.utcnow().isoformat(),\n",
    "            },\n",
    "            headers={\n",
    "                \"x-api-key\": _LANGSMITH_API_KEY\n",
    "            }\n",
    "        )\n",
    "        \n",
    "logger = RunLogger()\n",
    "\n",
    "def fibonacci(n: int, depth: int = 0, parent_run_id: Optional[str] = None) -> int:\n",
    "    run_id = str(uuid.uuid4())\n",
    "    logger.post_run({\"n\": n}, f\"fibonacci_recursive\", run_id, parent_run_id=parent_run_id)\n",
    "    try:\n",
    "        if n <= 1:\n",
    "            result = n\n",
    "        else:\n",
    "            result = fibonacci(n - 1, depth + 1, parent_run_id=run_id) + fibonacci(n - 2, depth + 1, parent_run_id=run_id)\n",
    "        logger.patch_run(run_id, output={\"result\": result})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.patch_run(run_id, error=str(e))\n",
    "        raise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e087cb60-1e12-48d5-8788-7cdab59993db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fibonacci(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c713dff-7df2-4822-895a-1fd872bfc471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will show what the trace looks like with an error\n",
    "try:\n",
    "    fibonacci(3, depth=\"Wrong Type\")\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
