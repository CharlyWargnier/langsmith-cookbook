{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79036a8c",
   "metadata": {},
   "source": [
    "# Tracing Without LangChain\n",
    "\n",
    "LangSmith lets you instrument applications even if you don't want to depend on LangChain itself. The following is an example chat application using the raw openai SDK. First, install langsmith and the openai SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5615479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U pip > /dev/null\n",
    "%pip install -U langsmith > /dev/null\n",
    "%pip install -U openai > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ebe2c0",
   "metadata": {},
   "source": [
    "Next, configure the API Key in the environment to make sure traces are logged to your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env LANGCHAIN_API_KEY=<your-api-key>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595e6dfe",
   "metadata": {},
   "source": [
    "Next, define your chat application. Here we will use the `traceable` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ba8c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Optional, Tuple\n",
    "from langsmith.run_helpers import traceable\n",
    "\n",
    "\n",
    "def call_openai(data: List[dict], model: str = \"gpt-3.5-turbo\", temperature: float = 0.0, run_tree: RunTree):\n",
    "    child = run_tree.get_child(\n",
    "        name=\"ChatOpenAI\",\n",
    "        inputs={\"data\": data, \"model\": model, \"temperature\": temperature},\n",
    "        run_type=\"llm\",\n",
    "    )\n",
    "    try:\n",
    "        result = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=data,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        child.end(outputs={\"response\": result})\n",
    "        child.post()\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        child.end(error=str(e))\n",
    "        child.post()\n",
    "        raise\n",
    "\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def argument_generator(query: str, additional_description: str = \"\") -> str:\n",
    "    return call_openai(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": f\"You are a debater making an argument on a topic.\"\n",
    "             f\"{additional_description}\"\n",
    "             f\" The current time is {datetime.now()}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"The discussion topic is {query}\"}\n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def critic(argument: str) -> str:\n",
    "    return call_openai(\n",
    "        [ \n",
    "            {\"role\": \"system\", \"content\": f\"You are a critic.\"\n",
    "           \"\\nWhat unresolved questions or criticism do you have after reading the following argument?\"\n",
    "            \"Provide a concise summary of your feedback.\"},\n",
    "            {\"role\": \"system\", \"content\": argument}\n",
    "            \n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def refiner(query: str, additional_description: str, current_arg: str, criticism: str) -> str:\n",
    "    return call_openai(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": f\"You are a debater making an argument on a topic.\"\n",
    "             f\"{additional_description}\"\n",
    "             f\" The current time is {datetime.now()}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"The discussion topic is {query}\"},\n",
    "            {\"role\": \"assistant\", \"content\": current_arg},\n",
    "            {\"role\": \"user\", \"content\": criticism},\n",
    "            {\"role\": \"system\", \"content\": \"Please generate a new argument that incorporates the feedback from the user.\"}\n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "\n",
    "@traceable(run_type=\"chain\")      \n",
    "def argument_chain(query: str, additional_description: str = \"\") -> str:\n",
    "    argument = argument_generator(query, additional_description)\n",
    "    criticism = critic(argument)\n",
    "    return refiner(query, additional_description, argument, criticism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9c92472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Argument:\n",
      "Sunshine is good for you because it provides essential vitamin D, which is crucial for bone health, immune function, and mental well-being. Additionally, exposure to sunlight can improve mood, increase serotonin levels, and promote better sleep patterns.\n",
      "Criticism:\n",
      "The argument presents a one-sided view of the benefits of sunshine without acknowledging any potential drawbacks or limitations. It fails to address the potential risks of excessive sun exposure, such as skin damage and an increased risk of skin cancer. Additionally, the argument does not provide any evidence or research to support its claims about the positive effects of sunlight on mental well-being, mood, serotonin levels, and sleep patterns. Therefore, the argument lacks balance and credibility.\n",
      "Refined argument:\n",
      "Sunshine, in moderation, is good for you because it provides essential vitamin D, which is crucial for bone health, immune function, and mental well-being. However, it is important to acknowledge the potential risks of excessive sun exposure, such as skin damage and an increased risk of skin cancer. By practicing sun safety measures, such as wearing sunscreen and seeking shade during peak hours, one can enjoy the benefits of sunshine while minimizing the potential drawbacks. Additionally, research suggests that sunlight exposure can positively impact mood and mental health by increasing serotonin levels and regulating sleep patterns.\n",
      "Stopping\n"
     ]
    }
   ],
   "source": [
    "result = argument_chain(\n",
    "    \"Whether sunshine is good for you.\", \n",
    "    additional_description=\"Provide a concise, few sentence argument on why sunshine is good for you.\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad8af8",
   "metadata": {},
   "source": [
    "## Capturing the runs\n",
    "\n",
    "The `traceable` decorator will inject the current `RunTree` object into the traced function if the argument is provided. You can use this to do things like fetch the run ID. Below, our `Chat2` app is an identical to the previous one but views the injected run_tree so we can fetch the latest run. The chat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "117dca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import RunTree\n",
    "    \n",
    "run_ids = []\n",
    "    \n",
    "@traceable(run_type=\"chain\")      \n",
    "def argument_chain2(query: str, run_tree: RunTree,additional_description: str = \"\") -> str:\n",
    "    argument = argument_generator(query, additional_description)\n",
    "    run_ids.append(run_tree.id)\n",
    "    criticism = critic(argument)\n",
    "    return refiner(query, additional_description, argument, criticism)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b339dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Argument:\n",
      "Sunshine is good for you because it provides essential vitamin D, which is crucial for bone health, immune function, and mental well-being. Additionally, exposure to sunlight can improve mood, increase serotonin levels, and promote better sleep patterns, ultimately leading to a healthier and happier life.\n",
      "Criticism:\n",
      "The argument presents a one-sided view of the benefits of sunshine without acknowledging any potential drawbacks or limitations. It fails to address the potential risks of excessive sun exposure, such as skin damage and an increased risk of skin cancer. Additionally, the argument does not provide any evidence or research to support its claims about the impact of sunlight on mental well-being and sleep patterns. A more balanced and evidence-based approach is needed to fully evaluate the effects of sunshine on overall health.\n",
      "Refined argument:\n",
      "Sunshine, in moderation, is good for you because it provides essential vitamin D, which is crucial for bone health, immune function, and mental well-being. However, it is important to acknowledge the potential risks of excessive sun exposure, such as skin damage and an increased risk of skin cancer. By practicing sun safety measures, such as wearing sunscreen and seeking shade during peak hours, individuals can enjoy the benefits of sunshine while minimizing the potential drawbacks. Additionally, while there is anecdotal evidence suggesting that sunlight can improve mood and sleep patterns, further research is needed to fully understand and establish the causal relationship between sunlight and mental well-being.\n",
      "Stopping\n"
     ]
    }
   ],
   "source": [
    "result = argument_chain2(\n",
    "    \"Whether sunshine is good for you.\", \n",
    "    additional_description=\"Provide a concise, few sentence argument on why sunshine is good for you.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c080ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_id = run_ids[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e45a0845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000px\"\n",
       "            height=\"520px\"\n",
       "            src=\"https://dev.smith.langchain.com/public/4708dc0b-817b-425c-844c-1654f052430a/r?zoom=50\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x159e63710>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "shared_link = client.share_run(latest_id)\n",
    "\n",
    "from IPython.display import IFrame\n",
    "# Here's an example run:\n",
    "IFrame(shared_link, width='1000px', height='520px', zoom=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1e02471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dev.smith.langchain.com/public/4708dc0b-817b-425c-844c-1654f052430a/r'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc2929",
   "metadata": {},
   "source": [
    "## Using the RunTree\n",
    "\n",
    "The `traceable` decorator is lightweight but less flexible when it comes to defining the schema of the logs you want to save. Below, we will make an example of the chat application that logs runs using the RunTree object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "561b3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(data: List[dict], run_tree: RunTree,  model: str = \"gpt-3.5-turbo\", temperature: float = 0.0):\n",
    "    child = run_tree.create_child(\n",
    "        name=\"ChatOpenAI\",\n",
    "        inputs={\"data\": data, \"model\": model, \"temperature\": temperature},\n",
    "        run_type=\"llm\",\n",
    "    )\n",
    "    child.post()\n",
    "    try:\n",
    "        result = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=data,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        child.end(outputs={\"response\": result})\n",
    "    except Exception as e:\n",
    "        child.end(error=str(e))\n",
    "        raise\n",
    "    finally:\n",
    "        child.patch()\n",
    "    return result\n",
    "\n",
    "\n",
    "def argument_generator(query: str, run_tree: RunTree, additional_description: str = \"\") -> str:\n",
    "    child = run_tree.create_child(name=\"ArgumentGenerator\", inputs={\"query\": query, additional_description: additional_description}, run_type=\"chain\")\n",
    "    child.post()\n",
    "    try:\n",
    "        result = call_openai(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": f\"You are a debater making an argument on a topic.\"\n",
    "                    f\"{additional_description}\"\n",
    "                    f\" The current time is {datetime.now()}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"The discussion topic is {query}\"}\n",
    "            ], run_tree=child\n",
    "        ).choices[0].message.content\n",
    "        child.end(outputs={\"argument\": result})\n",
    "    except Exception as e:\n",
    "        child.end(error=str(e))\n",
    "        raise\n",
    "    finally:\n",
    "        child.patch()\n",
    "    return result\n",
    "\n",
    "\n",
    "def critic(argument: str, run_tree: RunTree) -> str:\n",
    "    child = run_tree.create_child(name=\"Critic\", run_type=\"chain\", inputs={\"argument\": argument})\n",
    "    child.post()\n",
    "    try:\n",
    "        result = call_openai(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": f\"You are a critic.\"\n",
    "                    \"\\nWhat unresolved questions or criticism do you have after reading the following argument?\"\n",
    "                    \"Provide a concise summary of your feedback.\"},\n",
    "                {\"role\": \"system\", \"content\": argument}\n",
    "            ], run_tree=child\n",
    "        ).choices[0].message.content\n",
    "        child.end(outputs={\"criticism\": result})\n",
    "    except Exception as e:\n",
    "        child.end(error=str(e))\n",
    "        raise\n",
    "    finally:\n",
    "        child.patch()\n",
    "    return result\n",
    "\n",
    "\n",
    "def refiner(query: str, additional_description: str, current_arg: str, criticism: str, run_tree: RunTree) -> str:\n",
    "    child = run_tree.create_child(name=\"Refiner\", run_type=\"chain\", inputs={\"query\": query, \"additional_description\": additional_description})\n",
    "    child.post()\n",
    "    try:\n",
    "        result = call_openai(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": f\"You are a debater making an argument on a topic.\"\n",
    "                    f\"{additional_description}\"\n",
    "                    f\" The current time is {datetime.now()}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"The discussion topic is {query}\"},\n",
    "                {\"role\": \"assistant\", \"content\": current_arg},\n",
    "                {\"role\": \"user\", \"content\": criticism},\n",
    "                {\"role\": \"system\", \"content\": \"Please generate a new argument that incorporates the feedback from the user.\"}\n",
    "            ], run_tree=child\n",
    "        ).choices[0].message.content\n",
    "        child.end(outputs={\"refined_argument\": result})\n",
    "    except Exception as e:\n",
    "        child.end(error=str(e))\n",
    "        raise\n",
    "    finally:\n",
    "        child.patch()\n",
    "    return result\n",
    "    \n",
    "\n",
    "run_tree_run_ids = []\n",
    "def argument_chain3(query: str, additional_description: str = \"\", run_tree: RunTree = None) -> str:\n",
    "    inputs = {\n",
    "        \"query\": query,\n",
    "        \"additional_description\": additional_description\n",
    "    }\n",
    "    if run_tree is None:\n",
    "        argument_run_tree = RunTree(name=\"ArgumentChain\", run_type=\"chain\", inputs=inputs)\n",
    "    else:\n",
    "        argument_run_tree = run_tree.create_child(name=\"ArgumentChain\", run_type=\"chain\", inputs=inputs)\n",
    "    argument_run_tree.post()\n",
    "    run_tree_run_ids.append(argument_run_tree.id)\n",
    "    try:\n",
    "        argument = argument_generator(query, additional_description=additional_description, run_tree=argument_run_tree)\n",
    "        criticism = critic(argument, run_tree=argument_run_tree)\n",
    "        result = refiner(query, additional_description, argument, criticism, run_tree=argument_run_tree)\n",
    "        argument_run_tree.end(outputs={\"final_argument\": result})\n",
    "    except Exception as e:\n",
    "        argument_run_tree.end(error=str(e))\n",
    "        raise\n",
    "    finally:\n",
    "        argument_run_tree.patch()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "728bc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = argument_chain3(\n",
    "    \"Whether sunshine is good for you.\", \n",
    "    additional_description=\"Provide a concise, few sentence argument on why sunshine is good for you.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38d8eed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dev.smith.langchain.com/public/e11a654c-18fc-4f59-ad27-83f5445eaaf5/r'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_id = run_tree_run_ids[-1]\n",
    "shared_link = client.share_run(latest_id)\n",
    "shared_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb64f1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000px\"\n",
       "            height=\"520px\"\n",
       "            src=\"https://dev.smith.langchain.com/public/e11a654c-18fc-4f59-ad27-83f5445eaaf5/r?zoom=50\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x15a011a10>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's an example run:\n",
    "IFrame(shared_link, width='1000px', height='520px', zoom=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14704a51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
