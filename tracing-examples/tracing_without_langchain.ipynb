{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79036a8c",
   "metadata": {},
   "source": [
    "# Tracing Without LangChain\n",
    "\n",
    "LangSmith lets you instrument **any LLM application,** no LangChain required. This can help you debug, evaluate, and monitor your app without having to learn any particular framework's unique semantics.\n",
    "\n",
    "The basic tracing functionality works by posting `run` messages to the LangSmith platform. Runs are structured log messages organized within call hierarchy for each trace. Though you can manually create runs using the `Client` or REST API, LangSmith provides two recommended ways to instrument your application in python (there currently is just the `RunTree` for js):\n",
    "\n",
    "1. Using a `RunTree`\n",
    "2. Using the `@traceable` decorator, which manages the RunTree lifecycle on your behalf.\n",
    "\n",
    "In the following walkthrough, you will create an example app using the `@traceable` decorator and explore some configurations you can do for logging auxiliary information.\n",
    "\n",
    "The example chat app used in this walkthrough generates an argument about a topic. It is composed of three separate components, which will all show up in the traces:\n",
    "\n",
    "1. An argument generation function\n",
    "2. Critique function\n",
    "3. Refine function\n",
    "\n",
    "Each of these \"chain\" functions will call an openai `llm` function, and the whole series of calls will itself be organized beneath a parent `argument_chain` function.\n",
    "\n",
    "Put together, the program will generate a trace like the following:\n",
    "\n",
    "![RunTree 1](img/snapshot_1.png)\n",
    "\n",
    "Now that we know what we're building, let's get started!\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Let's first install some required packages. We'll need both the langsmith SDK and the OpenAI SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5615479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langsmith > /dev/null\n",
    "%pip install -U openai > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ebe2c0",
   "metadata": {},
   "source": [
    "Next, configure the API Key in the environment to make sure traces are logged to your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f665dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env LANGCHAIN_API_KEY=<your-api-key>\n",
    "%env LANGCHAIN_PROJECT=tracing-cookbook-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17285047",
   "metadata": {},
   "source": [
    "## Using the decorator\n",
    "\n",
    "Next, define your chat application. Use the `@traceable` decorator to automatically instrument your\n",
    "function calls.\n",
    "\n",
    "The decorator works by creating a run tree for you each time the function is called. The function inputs, name, and other information is added to the tree and streamed to LangSmith. If the function raises an error or if it returns a response, that information is also added to the tree, and updates are sent to LangSmith. This is all done on a background thread to avoid blocking your app's execution.\n",
    "\n",
    "The app below combines three `chain` runs, which each call an openai `llm` function. The `llm` run type corresponds to any LLM or chat model call. We recommend that you type all other general functions as `chain` runs, as these are the most general-purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba8c359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import openai\n",
    "from langsmith.run_helpers import traceable\n",
    "\n",
    "\n",
    "# We will label this function as an \"llm\" call to organize and render it better in the web app\n",
    "@traceable(run_type=\"llm\")\n",
    "def call_openai(data: List[dict], model: str = \"gpt-3.5-turbo\", temperature: float = 0.0):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=data,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "\n",
    "# 'Chain' run_type's can correspond to any function and are the most common traced run\n",
    "@traceable(run_type=\"chain\")\n",
    "def argument_generator(query: str, additional_description: str = \"\") -> str:\n",
    "    return call_openai(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": f\"You are a debater making an argument on a topic.\"\n",
    "             f\"{additional_description}\"\n",
    "             f\" The current time is {datetime.now()}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"The discussion topic is {query}\"}\n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def critic(argument: str) -> str:\n",
    "    return call_openai(\n",
    "        [ \n",
    "            {\"role\": \"system\", \"content\": f\"You are a critic.\"\n",
    "           \"\\nWhat unresolved questions or criticism do you have after reading the following argument?\"\n",
    "            \"Provide a concise summary of your feedback.\"},\n",
    "            {\"role\": \"system\", \"content\": argument}\n",
    "            \n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def refiner(query: str, additional_description: str, current_arg: str, criticism: str) -> str:\n",
    "    return call_openai(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": f\"You are a debater making an argument on a topic.\"\n",
    "             f\"{additional_description}\"\n",
    "             f\" The current time is {datetime.now()}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"The discussion topic is {query}\"},\n",
    "            {\"role\": \"assistant\", \"content\": current_arg},\n",
    "            {\"role\": \"user\", \"content\": criticism},\n",
    "            {\"role\": \"system\", \"content\": \"Please generate a new argument that incorporates the feedback from the user.\"}\n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "\n",
    "@traceable(run_type=\"chain\")      \n",
    "def argument_chain(query: str, additional_description: str = \"\") -> str:\n",
    "    argument = argument_generator(query, additional_description)\n",
    "    criticism = critic(argument)\n",
    "    return refiner(query, additional_description, argument, criticism)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb9f73",
   "metadata": {},
   "source": [
    "Now call the chain. If you set up your API key correctly at the start of this notebook, all the results should be traced to  [LangSmith](https://www.smith.langchain.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f5798a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunshine, in moderation, is good for you because it provides essential vitamin D, which is crucial for bone health, immune function, and mental well-being. However, it is important to acknowledge the potential risks of excessive sun exposure, such as skin damage and an increased risk of skin cancer. By practicing sun safety measures, such as wearing sunscreen and seeking shade during peak hours, individuals can enjoy the benefits of sunshine while minimizing the potential drawbacks. Additionally, while there is anecdotal evidence suggesting that sunlight can improve mood and sleep patterns, further research is needed to fully understand and establish the causal relationship between sunlight and mental well-being.\n"
     ]
    }
   ],
   "source": [
    "result = argument_chain(\n",
    "    \"Whether sunshine is good for you.\", \n",
    "    additional_description=\"Provide a concise, few sentence argument on why sunshine is good for you.\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad8af8",
   "metadata": {},
   "source": [
    "## Working with runs\n",
    "\n",
    "The above is all you need to save your app traces to LangSmith! The decorator handles the call relationships for you in a background thread to avoid interfering with your program execution. You can try adding exceptions or other information to the functions to see how those are shown in the app.\n",
    "\n",
    "Beyond tracing, you may want to use LangSmith for other things like monitoring user feedback. You can view the run information by looking at the `RunTree` created for that event. To do so, change any wrapped function's signature to accept a `run_tree` argument. Then the `@traceable` decorator will inject the current run tree object into the wrapped function. This can be useful if you want to:\n",
    "- Add user feedback to the run\n",
    "- Inspect or save the run ID or its parent\n",
    "- Manually log child runs or their information to another destination\n",
    "- Explicitly pass the run tree to other functions that may be called within thread or process pools (or on separate machines) to maintain trace cohesion\n",
    "\n",
    "Below, our `argument_chain2` function is identical to the previous one but views the injected run_tree so we can fetch the latest run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117dca62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langsmith import RunTree\n",
    "    \n",
    "@traceable(run_type=\"chain\")      \n",
    "def argument_chain2(query: str, *, additional_description: str = \"\", run_tree: RunTree) -> str:\n",
    "    argument = argument_generator(query, additional_description)\n",
    "    criticism = critic(argument)\n",
    "    refined_argument = refiner(query, additional_description, argument, criticism)       \n",
    "    return refined_argument, run_tree.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b339dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result, run_id = argument_chain2(\n",
    "    \"Whether sunshine is good for you.\", \n",
    "    additional_description=\"Provide a concise, few sentence argument on why sunshine is good for you.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c8ea3",
   "metadata": {},
   "source": [
    "View the run ID that you've collected and then create a public link to share. You could also add the ID to other logs or instrumentation in your app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e45a0845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7b378c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedback(id=UUID('a27e9cb3-e42a-4f29-8aca-68c851c30f6d'), created_at=datetime.datetime(2023, 8, 9, 4, 55, 29, 179158), modified_at=datetime.datetime(2023, 8, 9, 4, 55, 29, 179164), run_id=UUID('ae0e4090-300f-478d-913d-dcaf03ce8448'), key='user_feedback', score=0.5, value=None, comment=None, correction={'generation': 'Sunshine is nice. Full stop.'}, feedback_source=FeedbackSourceBase(type='api', metadata=None))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_feedback(\n",
    "    run_id,\n",
    "    \"user_feedback\",\n",
    "    score=0.5,\n",
    "    correction={\"generation\": \"Sunshine is nice. Full stop.\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa2adcf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/public/7e7b6caa-80bc-41af-bed1-35cd1011de77/r'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use run_id's to create shared links\n",
    "shared_link = client.share_run(run_id)\n",
    "shared_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656dd86",
   "metadata": {},
   "source": [
    "[![RunTree 2](./img/snapshot_2.png)]('https://smith.langchain.com/public/7e7b6caa-80bc-41af-bed1-35cd1011de77/r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc2fad",
   "metadata": {},
   "source": [
    "## Configuring Traces\n",
    "\n",
    "One way to make your application traces more useful or actionable is to tag or add metadata to the logs. That way you can do things like track the version of your code or deployment environment in a single project.\n",
    "\n",
    "The traceable decorator can be configured to add additional information such as:\n",
    "- string tags\n",
    "- arbitrary key-value metadata\n",
    "- custom trace names\n",
    "- manually-specified run ID\n",
    "\n",
    "Below is an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac98115b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can add tags and metadata (or even the project name) directly in the decorator\n",
    "@traceable(run_type=\"chain\", name=\"My Argument Chain\", tags=[\"tutorial\"], metadata={\"githash\": \"e38f04c83\"})      \n",
    "def argument_chain_3(query: str, additional_description: str = \"\") -> str:\n",
    "    argument = argument_generator(query, additional_description)\n",
    "    criticism = critic(argument)\n",
    "    return refiner(query, additional_description, argument, criticism)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "217e03ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "requested_uuid = uuid4()\n",
    "\n",
    "result = argument_chain_3(\n",
    "    \"Whether sunshine is good for you.\", \n",
    "    additional_description=\"Provide a concise, few sentence argument on why sunshine is good for you.\",\n",
    "    # You can also add tags, metadata, or the run ID directly via arguments to the langsmith_extra argument\n",
    "    # at all-time.\n",
    "    langsmith_extra={\n",
    "        \"tags\": [\"another-tag\"],\n",
    "        \"metadata\": {\"another-key\": 1},\n",
    "        \"run_id\": requested_uuid,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de84533a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedback(id=UUID('43d50b3d-a341-4863-a102-b7e8af0524c7'), created_at=datetime.datetime(2023, 8, 9, 4, 57, 12, 43727), modified_at=datetime.datetime(2023, 8, 9, 4, 57, 12, 43732), run_id=UUID('7830a736-566a-496c-8d5d-2f1f4ad56ed9'), key='user_feedback', score=1.0, value=None, comment=None, correction=None, feedback_source=FeedbackSourceBase(type='api', metadata={'origin': 'example notebook'}))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can log feedback for the run directly since we've controlled the ID it's assuming\n",
    "client.create_feedback(\n",
    "    requested_uuid,\n",
    "    \"user_feedback\",\n",
    "    score=1,\n",
    "    source_info={\"origin\": \"example notebook\"}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b955cab",
   "metadata": {},
   "source": [
    "Now you can navigate to the run with the requested UUID to see the simulated \"user feedback\".\n",
    "\n",
    "[![Tagged Run Tree](./img/snapshot_3.png)](https://dev.smith.langchain.com/public/502a9bc4-44b1-4e86-bb19-3d6b9766f248/r)\n",
    "\n",
    "Clicking in to the 'Metadata' tab, you can see the metadata has been stored for the trace.\n",
    "\n",
    "[![Run Tree Metadata](./img/snapshot_3_metadata.png)](https://dev.smith.langchain.com/public/502a9bc4-44b1-4e86-bb19-3d6b9766f248/r?tab=2)\n",
    "\n",
    "Once you've stored these tagged runs, you can filter and search right in the web app by clicking on the suggested filters or by writing out the query in the search bar:\n",
    "\n",
    "\n",
    "![Filtering Tags](./img/snapshot_3_tag_filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d212bffc-9798-43af-8dd7-d3c5fbf72582",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "In this walkthrough, you made an example LLM application and instrumented it using the `@traceable` decorator from the LangSmith SDK.\n",
    "\n",
    "You also added tags and metadata and even logged feedback to the runs. The traceable decorator is a light-weight and flexible way to start debugging and monitoring your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da52b71-0328-4186-8e28-07ad6b619c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
