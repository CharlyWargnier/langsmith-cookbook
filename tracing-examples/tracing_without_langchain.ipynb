{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79036a8c",
   "metadata": {},
   "source": [
    "# Tracing Without LangChain\n",
    "\n",
    "LangSmith lets you instrument **any LLM application,** no LangChain required. This can help you debug, evaluate, and monitor your app without having to learn any particular framework's unique semantics. LangSmith provides two primary ways to do this in python (there currently is just the `RunTree` for js):\n",
    "\n",
    "1. Using the `@traceable` decorator\n",
    "2. Using a `RunTree`\n",
    "\n",
    "In the following walkthrough, you will create an example app using the traceable decorator and explore some configurations you can do for logging auxiliary information. Then you will rewrite the app using the RunTree for more control.\n",
    "\n",
    "The chat app used in this walkthrough generates an argument about a topic. It is composed of three separate components, which will all show up in the traces:\n",
    "\n",
    "1. An argument generation function\n",
    "2. Critique function\n",
    "3. Refine function\n",
    "\n",
    "Each of these \"chain\" functions will call an openai `llm` function, and the whole series of calls will itself be organized beneath a parent `argument_chain` function.\n",
    "\n",
    "Put together, the program will generate a trace like the following:\n",
    "\n",
    "![RunTree 1](img/snapshot_1.png)\n",
    "\n",
    "Now that we know what we're building, let's get started!\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Let's first install some required packages. We'll need both the langsmith SDK and the OpenAI SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5615479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langsmith > /dev/null\n",
    "%pip install -U openai > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ebe2c0",
   "metadata": {},
   "source": [
    "Next, configure the API Key in the environment to make sure traces are logged to your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f665dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env LANGCHAIN_API_KEY=<your-api-key>\n",
    "# %env LANGCHAIN_PROJECT=tracing-cookbook-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17285047",
   "metadata": {},
   "source": [
    "## Using the decorator\n",
    "\n",
    "Next, define your chat application. Use the `@traceable` decorator to automatically instrument your\n",
    "function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba8c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import openai\n",
    "from langsmith.run_helpers import traceable\n",
    "\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def call_openai(data: List[dict], model: str = \"gpt-3.5-turbo\", temperature: float = 0.0):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=data,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def argument_generator(query: str, additional_description: str = \"\") -> str:\n",
    "    return call_openai(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": f\"You are a debater making an argument on a topic.\"\n",
    "             f\"{additional_description}\"\n",
    "             f\" The current time is {datetime.now()}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"The discussion topic is {query}\"}\n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def critic(argument: str) -> str:\n",
    "    return call_openai(\n",
    "        [ \n",
    "            {\"role\": \"system\", \"content\": f\"You are a critic.\"\n",
    "           \"\\nWhat unresolved questions or criticism do you have after reading the following argument?\"\n",
    "            \"Provide a concise summary of your feedback.\"},\n",
    "            {\"role\": \"system\", \"content\": argument}\n",
    "            \n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def refiner(query: str, additional_description: str, current_arg: str, criticism: str) -> str:\n",
    "    return call_openai(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": f\"You are a debater making an argument on a topic.\"\n",
    "             f\"{additional_description}\"\n",
    "             f\" The current time is {datetime.now()}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"The discussion topic is {query}\"},\n",
    "            {\"role\": \"assistant\", \"content\": current_arg},\n",
    "            {\"role\": \"user\", \"content\": criticism},\n",
    "            {\"role\": \"system\", \"content\": \"Please generate a new argument that incorporates the feedback from the user.\"}\n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "\n",
    "@traceable(run_type=\"chain\")      \n",
    "def argument_chain(query: str, additional_description: str = \"\") -> str:\n",
    "    argument = argument_generator(query, additional_description)\n",
    "    criticism = critic(argument)\n",
    "    return refiner(query, additional_description, argument, criticism)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb9f73",
   "metadata": {},
   "source": [
    "Now call the chain. If you set up your API key correctly at the start of this notebook, all the results should be traced to  [LangSmith](https://www.smith.langchain.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5798a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While it is true that excessive sun exposure can lead to sunburn, skin damage, and an increased risk of skin cancer, it is important to acknowledge that moderate and responsible exposure to sunshine can have significant health benefits. Sunlight is a natural source of vitamin D, which plays a crucial role in bone health, immune function, and mental well-being. While dietary supplements can provide vitamin D, they may not be as effective as sunlight in raising vitamin D levels. By practicing sun safety measures, such as wearing sunscreen and seeking shade during peak hours, individuals can enjoy the benefits of sunshine while minimizing the potential risks.\n"
     ]
    }
   ],
   "source": [
    "result = argument_chain(\n",
    "    \"Whether sunshine is good for you.\", \n",
    "    additional_description=\"Provide a concise, few sentence argument on why sunshine is good for you.\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad8af8",
   "metadata": {},
   "source": [
    "## Working with runs\n",
    "\n",
    "The above is all you need to save your app traces to LangSmith! The decorator handles the call relationships for you in a background thread to avoid interfering with your program execution.\n",
    "\n",
    "Beyond tracing, you may want to use LangSmith for other things like monitoring user feedback. You can view the run information by looking at the `RunTree` created for that event. To do so, change any wrapped function's signature to accept a `run_tree` argument. Then the `@traceable` decorator will inject the current run tree object into the wrapped function. This can be useful if you want to:\n",
    "- Add user feedback to the run\n",
    "- Inspect or save the run ID or its parent\n",
    "- Manually log child runs or their information to another destination\n",
    "- Explicitly pass the run tree to other functions that may be called within thread or process pools (or on separate machines) to maintain trace cohesion\n",
    "\n",
    "Below, our `argument_chain2` function is identical to the previous one but views the injected run_tree so we can fetch the latest run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117dca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import RunTree\n",
    "    \n",
    "run_ids = []\n",
    "    \n",
    "@traceable(run_type=\"chain\")      \n",
    "def argument_chain2(query: str, *, additional_description: str = \"\", run_tree: RunTree) -> str:\n",
    "    argument = argument_generator(query, additional_description)\n",
    "    run_ids.append(run_tree.id)\n",
    "    criticism = critic(argument)\n",
    "    # If you want to manually provide the run tree to a 'traceable' function,\n",
    "    # You can pass it via the `langsmith_extra` arguments. This is optional!\n",
    "    return refiner(query, additional_description, argument, criticism, langsmith_extra={\"run_tree\": run_tree})       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b339dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = argument_chain2(\n",
    "    \"Whether sunshine is good for you.\", \n",
    "    additional_description=\"Provide a concise, few sentence argument on why sunshine is good for you.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c8ea3",
   "metadata": {},
   "source": [
    "View the run ID that you've collected and then create a public link to share. You could also add the ID to other logs or instrumentation in your app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45a0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf7b378c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedback(id=UUID('0979fb2b-aed7-45d8-b59a-7e64fc3f6b81'), created_at=datetime.datetime(2023, 8, 8, 22, 28, 12, 898173), modified_at=datetime.datetime(2023, 8, 8, 22, 28, 12, 898177), run_id=UUID('30fc332a-2810-48aa-87d3-b3a2e22e278c'), key='user_feedback', score=0.5, value=None, comment=None, correction={'generation': 'Sunshine is nice. Full stop.'}, feedback_source=FeedbackSourceBase(type='api', metadata=None))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_feedback(\n",
    "    run_ids[-1],\n",
    "    \"user_feedback\",\n",
    "    score=0.5,\n",
    "    correction={\"generation\": \"Sunshine is nice. Full stop.\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2adcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dev.smith.langchain.com/public/3138fe8d-e131-4359-bc0a-c0bef67d92f9/r'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_link = client.share_run(run_ids[-1])\n",
    "shared_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656dd86",
   "metadata": {},
   "source": [
    "![RunTree 2](./img/snapshot_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc2fad",
   "metadata": {},
   "source": [
    "## Configuring Traces\n",
    "\n",
    "One way to make your application traces more useful or actionable is to tag or add metadata to the logs. That way you can do things like track the version of your code or deployment environment in a single project.\n",
    "\n",
    "The traceable decorator can be configured to add additional information such as:\n",
    "- string tags\n",
    "- arbitrary key-value metadata\n",
    "- custom trace names\n",
    "- manually-specified run ID\n",
    "\n",
    "Below is an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac98115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add tags and metadata (or even the project name) directly in the decorator\n",
    "@traceable(run_type=\"chain\", name=\"My Argument Chain\", tags=[\"tutorial\"], metadata={\"githash\": \"e38f04c83\"})      \n",
    "def argument_chain_3(query: str, run_tree: RunTree, additional_description: str = \"\") -> str:\n",
    "    argument = argument_generator(query, additional_description)\n",
    "    run_ids.append(run_tree.id)\n",
    "    criticism = critic(argument)\n",
    "    # Passing the run tree via `langsmith_extra` is optional. It is automatically tracked in the background.\n",
    "    return refiner(query, additional_description, argument, criticism, langsmith_extra={\"run_tree\": run_tree})       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "217e03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "requested_uuid = uuid4()\n",
    "\n",
    "result = argument_chain_3(\n",
    "    \"Whether sunshine is good for you.\", \n",
    "    additional_description=\"Provide a concise, few sentence argument on why sunshine is good for you.\",\n",
    "    # You can also add tags, metadata, or the run ID directly via arguments to the langsmith_extra argument\n",
    "    # at all-time.\n",
    "    langsmith_extra={\n",
    "        \"tags\": [\"another-tag\"],\n",
    "        \"metadata\": {\"another-key\": 1},\n",
    "        \"run_id\": requested_uuid,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de84533a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedback(id=UUID('b99ccbb0-d33e-4106-aed8-34b50929d544'), created_at=datetime.datetime(2023, 8, 8, 22, 29, 51, 484809), modified_at=datetime.datetime(2023, 8, 8, 22, 29, 51, 484813), run_id=UUID('8f7a79b7-8c36-4b8f-911e-716e63913e0f'), key='user_feedback', score=1.0, value=None, comment=None, correction=None, feedback_source=FeedbackSourceBase(type='api', metadata={'origin': 'example notebook'}))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can log feedback for the run directly since we've controlled the ID it's assuming\n",
    "client.create_feedback(\n",
    "    run_ids[-1],\n",
    "    \"user_feedback\",\n",
    "    score=1,\n",
    "    source_info={\"origin\": \"example notebook\"}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5df720ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dev.smith.langchain.com/public/e06d142a-fd34-4479-9a06-4cd38200100d/r'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_link = client.share_run(requested_uuid)\n",
    "shared_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b955cab",
   "metadata": {},
   "source": [
    "You can see the tags are saved to the run linked above.\n",
    "\n",
    "[![Tagged Run Tree](./img/snapshot_3.png)](https://dev.smith.langchain.com/public/502a9bc4-44b1-4e86-bb19-3d6b9766f248/r)\n",
    "\n",
    "Clicking in to the 'Metadata' tab, you can see the metadata has been stored for the trace.\n",
    "\n",
    "[![Run Tree Metadata](./img/snapshot_3_metadata.png)](https://dev.smith.langchain.com/public/502a9bc4-44b1-4e86-bb19-3d6b9766f248/r?tab=2)\n",
    "\n",
    "Once you've stored these tagged runs, you can filter and search right in the web app by clicking on the suggested filters or by writing out the query in the search bar:\n",
    "\n",
    "\n",
    "![Filtering Tags](./img/snapshot_3_tag_filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc2929",
   "metadata": {},
   "source": [
    "## Manual tracing using the RunTree\n",
    "\n",
    "The `traceable` decorator is a lightweight and extremely easy way to instrument your app and stream traces to LangSmith. It is less flexible if you want to control things like the schema for how the logs are saved or how errors are displayed. Below, we will rewrite the chat application in a way that explicitly uses the run tree to save traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "561b3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import RunTree\n",
    "\n",
    "def call_openai(data: List[dict], run_tree: RunTree,  model: str = \"gpt-3.5-turbo\", temperature: float = 0.0):\n",
    "    child = run_tree.create_child(\n",
    "        name=\"ChatOpenAI\",\n",
    "        inputs={\"data\": data, \"model\": model, \"temperature\": temperature},\n",
    "        run_type=\"llm\",\n",
    "    )\n",
    "    child.post()\n",
    "    try:\n",
    "        result = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=data,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        child.end(outputs={\"response\": result})\n",
    "    except Exception as e:\n",
    "        child.end(error=str(e))\n",
    "        raise\n",
    "    finally:\n",
    "        child.patch()\n",
    "    return result\n",
    "\n",
    "\n",
    "def argument_generator(query: str, run_tree: RunTree, additional_description: str = \"\") -> str:\n",
    "    child = run_tree.create_child(name=\"ArgumentGenerator\", inputs={\"query\": query, additional_description: additional_description}, run_type=\"chain\")\n",
    "    child.post()\n",
    "    try:\n",
    "        result = call_openai(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": f\"You are a debater making an argument on a topic.\"\n",
    "                    f\"{additional_description}\"\n",
    "                    f\" The current time is {datetime.now()}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"The discussion topic is {query}\"}\n",
    "            ], run_tree=child\n",
    "        ).choices[0].message.content\n",
    "        child.end(outputs={\"argument\": result})\n",
    "    except Exception as e:\n",
    "        child.end(error=str(e))\n",
    "        raise\n",
    "    finally:\n",
    "        child.patch()\n",
    "    return result\n",
    "\n",
    "\n",
    "def critic(argument: str, run_tree: RunTree) -> str:\n",
    "    child = run_tree.create_child(name=\"Critic\", run_type=\"chain\", inputs={\"argument\": argument})\n",
    "    child.post()\n",
    "    try:\n",
    "        result = call_openai(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": f\"You are a critic.\"\n",
    "                    \"\\nWhat unresolved questions or criticism do you have after reading the following argument?\"\n",
    "                    \"Provide a concise summary of your feedback.\"},\n",
    "                {\"role\": \"system\", \"content\": argument}\n",
    "            ], run_tree=child\n",
    "        ).choices[0].message.content\n",
    "        child.end(outputs={\"criticism\": result})\n",
    "    except Exception as e:\n",
    "        child.end(error=str(e))\n",
    "        raise\n",
    "    finally:\n",
    "        child.patch()\n",
    "    return result\n",
    "\n",
    "\n",
    "def refiner(query: str, additional_description: str, current_arg: str, criticism: str, run_tree: RunTree) -> str:\n",
    "    child = run_tree.create_child(name=\"Refiner\", run_type=\"chain\", inputs={\"query\": query, \"additional_description\": additional_description})\n",
    "    child.post()\n",
    "    try:\n",
    "        result = call_openai(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": f\"You are a debater making an argument on a topic.\"\n",
    "                    f\"{additional_description}\"\n",
    "                    f\" The current time is {datetime.now()}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"The discussion topic is {query}\"},\n",
    "                {\"role\": \"assistant\", \"content\": current_arg},\n",
    "                {\"role\": \"user\", \"content\": criticism},\n",
    "                {\"role\": \"system\", \"content\": \"Please generate a new argument that incorporates the feedback from the user.\"}\n",
    "            ], run_tree=child\n",
    "        ).choices[0].message.content\n",
    "        child.end(outputs={\"refined_argument\": result})\n",
    "    except Exception as e:\n",
    "        child.end(error=str(e))\n",
    "        raise\n",
    "    finally:\n",
    "        child.patch()\n",
    "    return result\n",
    "    \n",
    "\n",
    "run_tree_run_ids = []\n",
    "def argument_chain4(query: str, additional_description: str = \"\", run_tree: RunTree = None) -> str:\n",
    "    inputs = {\n",
    "        \"query\": query,\n",
    "        \"additional_description\": additional_description\n",
    "    }\n",
    "    if run_tree is None:\n",
    "        argument_run_tree = RunTree(name=\"ArgumentChain\", run_type=\"chain\", inputs=inputs)\n",
    "    else:\n",
    "        argument_run_tree = run_tree.create_child(name=\"ArgumentChain\", run_type=\"chain\", inputs=inputs)\n",
    "    argument_run_tree.post()\n",
    "    run_tree_run_ids.append(argument_run_tree.id)\n",
    "    try:\n",
    "        argument = argument_generator(query, additional_description=additional_description, run_tree=argument_run_tree)\n",
    "        criticism = critic(argument, run_tree=argument_run_tree)\n",
    "        result = refiner(query, additional_description, argument, criticism, run_tree=argument_run_tree)\n",
    "        argument_run_tree.end(outputs={\"final_argument\": result})\n",
    "    except Exception as e:\n",
    "        argument_run_tree.end(error=str(e))\n",
    "        raise\n",
    "    finally:\n",
    "        argument_run_tree.patch()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "728bc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = argument_chain4(\n",
    "    \"Whether sunshine is good for you.\", \n",
    "    additional_description=\"Provide a concise, few sentence argument on why sunshine is good for you.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d846394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dev.smith.langchain.com/public/091ebe86-f137-4079-ae8f-6db01e367801/r'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_id = run_tree_run_ids[-1]\n",
    "shared_link = client.share_run(latest_id)\n",
    "shared_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d67f8b0",
   "metadata": {},
   "source": [
    "![Manual Run Tree](./img/snapshot_4.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
