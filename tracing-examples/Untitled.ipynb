{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecdfb8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langsmith.wrappers.openai_wrapper import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c0798ac-3793-42ea-8d98-4b5cc0bc94a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens received as part of a normal call:\n",
      "''\n",
      "'{\n",
      "'\n",
      "' '\n",
      "' \"'\n",
      "'setup'\n",
      "'\":'\n",
      "' \"'\n",
      "'Why'\n",
      "' did'\n",
      "' the'\n",
      "' frog'\n",
      "' go'\n",
      "' to'\n",
      "' the'\n",
      "' bank'\n",
      "'?\",\n",
      "'\n",
      "' '\n",
      "' \"'\n",
      "'p'\n",
      "'unch'\n",
      "'line'\n",
      "'\":'\n",
      "' \"'\n",
      "'To'\n",
      "' get'\n",
      "' a'\n",
      "' new'\n",
      "' pad'\n",
      "'!\"\n",
      "'\n",
      "'}'\n",
      "''\n",
      "{'subject': 'frogs', 'text': '{\\n  \"setup\": \"Why did the frog go to the bank?\",\\n  \"punchline\": \"To get a new pad!\"\\n}'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function_call_gets_no_tokens.py\n",
    "\n",
    "from typing import Any\n",
    "from uuid import UUID\n",
    "\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.openai_functions import create_structured_output_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class CustomCallbackHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(\n",
    "        self,\n",
    "        token: str,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: UUID | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        print(f\"'{token}'\")  # wrap token in single quotes for visibility\n",
    "\n",
    "        return super().on_llm_new_token(\n",
    "            token, run_id=run_id, parent_run_id=parent_run_id, **kwargs\n",
    "        )\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    streaming=True,\n",
    "    callbacks=[CustomCallbackHandler()],\n",
    ")\n",
    "\n",
    "joke_parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "prompt_template = \"Tell me a joke about {subject}.\\n\\n{format_instructions}\"\n",
    "chat_prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": joke_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "\n",
    "def chain_as_normal_call(subject):\n",
    "    chain = LLMChain(llm=chat_model, prompt=chat_prompt)\n",
    "    return chain(subject)\n",
    "\n",
    "\n",
    "def chain_as_function_call(subject):\n",
    "    chain = create_structured_output_chain(Joke, llm=chat_model, prompt=chat_prompt)\n",
    "    return chain(subject)\n",
    "\n",
    "\n",
    "print(\"Tokens received as part of a normal call:\")\n",
    "normal_joke = chain_as_normal_call(\"frogs\")\n",
    "print(normal_joke)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ae1f477-dc17-4789-b69d-095616cc5edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aac385e-b8cc-4919-8d95-6f7efcb5e87e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ce051180d547dc9ce2cefc644a6ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52beeb57-4f9e-4b9c-b2f3-cdee1c07b571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error raised by inference API: Authorization header is correct, but the token seems invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m llm_chain\u001b[38;5;241m.\u001b[39marun(question)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrestult with load_qua_chain is....\u001b[39m\u001b[38;5;124m'\u001b[39m, result)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m run_chain()\n",
      "Cell \u001b[0;32mIn[22], line 27\u001b[0m, in \u001b[0;36mrun_chain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_chain\u001b[39m():\n\u001b[0;32m---> 27\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m llm_chain\u001b[38;5;241m.\u001b[39marun(question)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrestult with load_qua_chain is....\u001b[39m\u001b[38;5;124m'\u001b[39m, result)\n",
      "File \u001b[0;32m~/code/lc/langchain/libs/langchain/langchain/chains/base.py:535\u001b[0m, in \u001b[0;36marun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marun\u001b[39m(\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;241m*\u001b[39margs: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    502\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convenience method for executing chain.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03m    The main difference between this method and `Chain.__call__` is that this\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;124;03m    method expects inputs to be passed directly in as positional arguments or\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m    keyword arguments, whereas `Chain.__call__` expects a single input dictionary\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    with all the inputs\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \n\u001b[1;32m    510\u001b[0m \n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;124;03m        *args: If the chain expects a single input, it can be passed in as the\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m            sole positional argument.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m        callbacks: Callbacks to use for this chain run. These will be called in\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;124;03m            addition to callbacks passed to the chain during construction, but only\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;124;03m            these runtime callbacks will propagate to calls to other objects.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m        tags: List of string tags to pass to all callbacks. These will be passed in\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m            addition to tags passed to the chain during construction, but only\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m            these runtime tags will propagate to calls to other objects.\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m        **kwargs: If the chain expects multiple inputs, they can be passed in\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;124;03m            directly as keyword arguments.\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \n\u001b[1;32m    523\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;124;03m        The chain output.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \n\u001b[1;32m    526\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m        .. code-block:: python\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m            # Suppose we have a single-input chain that takes a 'question' string:\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m            await chain.arun(\"What's the temperature in Boise, Idaho?\")\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;124;03m            # -> \"The temperature in Boise is...\"\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \n\u001b[1;32m    533\u001b[0m \u001b[38;5;124;03m            # Suppose we have a multi-input chain that takes a 'question' string\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03m            # and 'context' string:\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;124;03m            question = \"What's the temperature in Boise, Idaho?\"\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;124;03m            context = \"Weather report for Boise, Idaho on 07/03/23...\"\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;124;03m            await chain.arun(question=question, context=context)\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m            # -> \"The temperature in Boise is...\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    542\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` not supported when there is not exactly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    543\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone output key. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         )\n",
      "File \u001b[0;32m~/code/lc/langchain/libs/langchain/langchain/chains/base.py:335\u001b[0m, in \u001b[0;36macall\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Asynchronously execute the chain.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_inputs(inputs)\n\u001b[1;32m    327\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m AsyncCallbackManager\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[1;32m    328\u001b[0m     callbacks,\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    331\u001b[0m     tags,\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags,\n\u001b[1;32m    333\u001b[0m     metadata,\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[0;32m--> 335\u001b[0m )\n\u001b[1;32m    336\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acall)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    337\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    338\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    339\u001b[0m     inputs,\n\u001b[1;32m    340\u001b[0m )\n",
      "File \u001b[0;32m~/code/lc/langchain/libs/langchain/langchain/chains/base.py:329\u001b[0m, in \u001b[0;36macall\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Asynchronously execute the chain.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_inputs(inputs)\n\u001b[1;32m    327\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m AsyncCallbackManager\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[1;32m    328\u001b[0m     callbacks,\n\u001b[0;32m--> 329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    331\u001b[0m     tags,\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags,\n\u001b[1;32m    333\u001b[0m     metadata,\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[1;32m    335\u001b[0m )\n\u001b[1;32m    336\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acall)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    337\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    338\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    339\u001b[0m     inputs,\n\u001b[1;32m    340\u001b[0m )\n",
      "File \u001b[0;32m~/code/lc/langchain/libs/langchain/langchain/chains/llm.py:234\u001b[0m, in \u001b[0;36m_acall\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    230\u001b[0m         result \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: r[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]} \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result]\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acall\u001b[39m(\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    235\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    236\u001b[0m     run_manager: Optional[AsyncCallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    237\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    238\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/code/lc/langchain/libs/langchain/langchain/chains/llm.py:116\u001b[0m, in \u001b[0;36mLLMChain.agenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m prompts, stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maprep_prompts(input_list, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[1;32m    117\u001b[0m     prompts,\n\u001b[1;32m    118\u001b[0m     stop,\n\u001b[1;32m    119\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[1;32m    121\u001b[0m )\n",
      "File \u001b[0;32m~/code/lc/langchain/libs/langchain/langchain/llms/base.py:465\u001b[0m, in \u001b[0;36magenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_astream\u001b[39m(\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    452\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    456\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[GenerationChunk]:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    461\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m    462\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    463\u001b[0m     callbacks: Optional[Union[Callbacks, List[Callbacks]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m--> 465\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    466\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/code/lc/langchain/libs/langchain/langchain/llms/base.py:738\u001b[0m, in \u001b[0;36magenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m langchain\u001b[38;5;241m.\u001b[39mllm_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m disregard_cache:\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache:\n\u001b[0;32m--> 738\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    739\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    740\u001b[0m         )\n\u001b[1;32m    741\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    742\u001b[0m         \u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m    743\u001b[0m             callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m         ]\n\u001b[1;32m    748\u001b[0m     )\n\u001b[1;32m    749\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [r[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m run_managers]\n",
      "File \u001b[0;32m~/code/lc/langchain/libs/langchain/langchain/llms/base.py:640\u001b[0m, in \u001b[0;36m_agenerate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_agenerate_helper\u001b[39m(\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    631\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    636\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    638\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    639\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(\n\u001b[0;32m--> 640\u001b[0m                 prompts,\n\u001b[1;32m    641\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    642\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    643\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    644\u001b[0m             )\n\u001b[1;32m    645\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    646\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    647\u001b[0m         )\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    650\u001b[0m             \u001b[38;5;241m*\u001b[39m[run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e) \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers]\n\u001b[1;32m    651\u001b[0m         )\n",
      "File \u001b[0;32m~/code/lc/langchain/libs/langchain/langchain/llms/base.py:627\u001b[0m, in \u001b[0;36m_agenerate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    626\u001b[0m generations \u001b[38;5;241m=\u001b[39m [existing_prompts[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(prompts))]\n\u001b[0;32m--> 627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations, llm_output\u001b[38;5;241m=\u001b[39mllm_output, run\u001b[38;5;241m=\u001b[39mrun_info)\n",
      "File \u001b[0;32m~/code/lc/langchain/libs/langchain/langchain/llms/base.py:981\u001b[0m, in \u001b[0;36m_agenerate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m    976\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    979\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    980\u001b[0m     )\n\u001b[0;32m--> 981\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/code/lc/langchain/libs/langchain/langchain/llms/base.py:965\u001b[0m, in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the LLM on the given prompt and input.\"\"\"\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    966\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    967\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    968\u001b[0m     run_manager: Optional[CallbackManagerForLLMRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    970\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    971\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the LLM on the given prompt and input.\"\"\"\u001b[39;00m\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;66;03m# TODO: add caching here.\u001b[39;00m\n",
      "File \u001b[0;32m~/code/lc/langchain/libs/langchain/langchain/llms/huggingface_hub.py:113\u001b[0m, in \u001b[0;36mHuggingFaceHub._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient(inputs\u001b[38;5;241m=\u001b[39mprompt, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError raised by inference API: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Text generation return includes the starter text.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     text \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mlen\u001b[39m(prompt) :]\n",
      "\u001b[0;31mValueError\u001b[0m: Error raised by inference API: Authorization header is correct, but the token seems invalid"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "import asyncio\n",
    "\n",
    "question = \"Who won the FIFA World Cup in the year 1994? \"\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm: HuggingFaceHub = HuggingFaceHub(\n",
    "\t\t\t\t\trepo_id=\"tiiuae/falcon-7b\",\n",
    "                    # repo_id=\"Qwen/Qwen-7B-Chat\",\n",
    "\t\t\t\t\thuggingfacehub_api_token=\"MY-TOKEN\",\n",
    "\t\t\t\t\tmodel_kwargs={\n",
    "\t\t\t\t\t\t\"temperature\": 0.5,\n",
    "\t\t\t\t\t\t \"max_length\": 64\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t)\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "async def run_chain():\n",
    "    result = await llm_chain.arun(question)\n",
    "    print('restult with load_qua_chain is....', result)\n",
    "\n",
    "await run_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace84a5a-0f7d-4329-bf92-ae389ff6d25b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens not received as part of a function call:\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "{'subject': 'frogs', 'function': Joke(setup='Why are frogs so happy?', punchline='Because they eat whatever bugs them!')}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens not received as part of a function call:\")\n",
    "function_joke = chain_as_function_call(\"frogs\")\n",
    "print(function_joke)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
