{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d1dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4fbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/harrisonchase/Downloads/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058349fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    (\"How old was the oldest person?\", \"df['Age'].max()\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0764058e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(\"df['Age'].max()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c02727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "client = Client()\n",
    "dataset_name = \"Dynamic Titantic CSV\"\n",
    "\n",
    "# Storing inputs in a dataset lets us\n",
    "# run chains and LLMs over a shared set of examples.\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name, description=\"Test QA over CSV\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a299865",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in questions:\n",
    "    client.create_example(\n",
    "        inputs={\"question\": example[0]},\n",
    "        outputs={\"code\": example[1]},\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "672dd395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74b12ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Answer the question {question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e66fb232",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8d074c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project '199ea00e87b64a9ea153ada938e33521-RunnableSequence' at:\n",
      "https://dev.langchain.plus/projects/p/b809b59e-3fed-4dd1-8f56-26e0955e5ca6?eval=true\n"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "from typing import Optional\n",
    "from langchain.evaluation.criteria.eval_chain import LabeledCriteriaEvalChain\n",
    "\n",
    "class CustomCriteriaEvalChain(LabeledCriteriaEvalChain):\n",
    "    \n",
    "    def _get_eval_input(\n",
    "        self,\n",
    "        prediction: str,\n",
    "        reference: Optional[str],\n",
    "        input: Optional[str],\n",
    "    ) -> dict:\n",
    "        raw = super()._get_eval_input(prediction, reference, input)\n",
    "        # This calculates the current reference answer, and uses that instead of the code\n",
    "        # This could be other things, like running a SQL query, hitting an API, etc\n",
    "        raw[\"reference\"] = eval(raw[\"reference\"])\n",
    "        return raw\n",
    "\n",
    "\n",
    "def get_chain():\n",
    "    return chain\n",
    "    \n",
    "\n",
    "client = Client()\n",
    "eval_config = RunEvalConfig(\n",
    "    custom_evaluators=[\n",
    "        CustomCriteriaEvalChain.from_llm(criteria=\"correctness\", llm=ChatOpenAI())\n",
    "    ],\n",
    ")\n",
    "chain_results = run_on_dataset(\n",
    "    client,\n",
    "    dataset_name=\"Dynamic Titantic CSV\",\n",
    "    llm_or_chain_factory=get_chain,\n",
    "    evaluation=eval_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e7c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
