{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analyze LangSmith Datasets with Lilac\n",
    "\n",
    "Lilac is an open-source product that helps you analyze, structure, and clean unstructured data with AI. \n",
    "\n",
    "Basic overview:\n",
    "- Create dataset from runs\n",
    "- Visualize the data\n",
    "- Query the dataset\n",
    "- Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -U \"lilac[pii]\" langdetect sentence-transformers langsmith --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create dataset of runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1621"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll start by fetching the root traces from a project\n",
    "from langsmith import Client\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "client = Client()\n",
    "\n",
    "project_name = \"chat-langchain\"\n",
    "start_time = datetime.now() - timedelta(days=7)\n",
    "\n",
    "\n",
    "runs = list(client.list_runs(\n",
    "    project_name=project_name,\n",
    "    start_time=start_time,\n",
    "    execution_order=1,\n",
    "    run_type=\"chain\",\n",
    "))\n",
    "len(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the dataset. We'll flatten some of the fields out to make it easiert to work with in Lilac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.smith.langchain.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.smith.langchain.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.smith.langchain.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.smith.langchain.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.smith.langchain.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: api.smith.langchain.com. Connection pool size: 10\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import json\n",
    "\n",
    "dataset_name = f\"{project_name}_EDA_dataset\"\n",
    "# client.delete_dataset(dataset_name=dataset_name)\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    ")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=30) as executor:\n",
    "    executor.map(\n",
    "        lambda run: client.create_example(\n",
    "            inputs={\n",
    "                # Lilac may have some issues on deeply nested structures\n",
    "                **{k: json.dumps(v) for k, v in run.inputs.items()},\n",
    "                \"run_name\": run.name,\n",
    "                \"latency\": (run.end_time - run.start_time).total_seconds(),\n",
    "            },\n",
    "            outputs={\n",
    "                **{k: json.dumps(v) for k, v in (run.outputs or {}).items()},\n",
    "                \"error\": str(run.error)\n",
    "            },\n",
    "            dataset_id=dataset.id,\n",
    "        ), \n",
    "        runs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From LangSmith Dataset\n",
    "\n",
    "Let's create a Lilac dataset from a LangSmith dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import lilac as ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from source langsmith...: 100%|██████████████████████████████████| 1616/1616 [00:00<00:00, 217354.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"chat-langchain_EDA_dataset\" written to data/datasets/local/chat-langchain_EDA_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_source = ll.sources.langsmith.LangSmithSource(\n",
    "    dataset_name=dataset_name,\n",
    ")\n",
    "\n",
    "config = ll.DatasetConfig(\n",
    "  namespace='local',\n",
    "  name=dataset_name,\n",
    "  source=data_source,\n",
    ")\n",
    "\n",
    "dataset = ll.create_dataset(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "Now that we have imported a few datasets, let's visualize them to see what they look like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [63729]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:5432 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling task \"90bf7d86052b4978916f0181302a7fec\": \"[local/chat-langchain_EDA_dataset] Compute signal \"openai\" on \"input\"\".\n",
      "Route error: http://127.0.0.1:5432/api/v1/datasets/local/chat-langchain_EDA_dataset/compute_signal\n",
      "Tried sending message after closing.  Status: closed\n",
      "Message: {'op': 'update-graph', 'graph_header': {'serializer': 'pickle', 'writeable': ()}, 'graph_frames': [b'\\x80\\x05\\x95\\x0b\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x1edistributed.protocol.serialize\\x94\\x8c\\x08ToPickle\\x94\\x93\\x94)\\x81\\x94}\\x94\\x8c\\x04data\\x94\\x8c\\x13dask.highlevelgraph\\x94\\x8c\\x0eHighLevelGraph\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x0cdependencies\\x94}\\x94\\x8a\\x05@\\x1d\\x12\\xd1\\x02\\x8f\\x94s\\x8c\\x10key_dependencies\\x94}\\x94\\x8c\\x06layers\\x94}\\x94\\x8a\\x05@\\x1d\\x12\\xd1\\x02h\\x06\\x8c\\x11MaterializedLayer\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x0bannotations\\x94N\\x8c\\x16collection_annotations\\x94N\\x8c\\x07mapping\\x94}\\x94\\x8c 90bf7d86052b4978916f0181302a7fec\\x94(\\x8c\\tfunctools\\x94\\x8c\\x07partial\\x94\\x93\\x94\\x8c\\x0blilac.tasks\\x94\\x8c\\r_execute_task\\x94\\x93\\x94\\x85\\x94R\\x94(h \\x8c\\x17cloudpickle.cloudpickle\\x94\\x8c\\x0e_make_function\\x94\\x93\\x94(h#\\x8c\\r_builtin_type\\x94\\x93\\x94\\x8c\\x08CodeType\\x94\\x85\\x94R\\x94(K\\x04K\\x00K\\x00K\\x06K\\x06K\\x13C\\x86\\x97\\x00t\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x03i\\x00|\\x02\\xa4\\x01\\x8e\\x01}\\x04t\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x00|\\x01\\xa6\\x02\\x00\\x00\\xab\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x05|\\x05\\xa0\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x04j\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x04j\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x03d\\x01f\\x02\\xac\\x02\\xa6\\x03\\x00\\x00\\xab\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00d\\x00S\\x00\\x94(NK\\x00\\x8c\\x0ctask_step_id\\x94\\x85\\x94)t\\x94(\\x8c\\x14ComputeSignalOptions\\x94\\x8c\\x0bget_dataset\\x94\\x8c\\x0ecompute_signal\\x94\\x8c\\x06signal\\x94\\x8c\\tleaf_path\\x94t\\x94(\\x8c\\tnamespace\\x94\\x8c\\x0cdataset_name\\x94\\x8c\\x0coptions_dict\\x94\\x8c\\x07task_id\\x94\\x8c\\x07options\\x94\\x8c\\x07dataset\\x94t\\x94\\x8cg/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lilac/router_dataset.py\\x94\\x8c\\x14_task_compute_signal\\x94\\x8c,compute_signal.<locals>._task_compute_signal\\x94KaCQ\\x80\\x00\\xf5\\x08\\x00\\x0f#\\xd0\\x0e2\\xd0\\x0e2\\xa0\\\\\\xd0\\x0e2\\xd0\\x0e2\\x80G\\xdd\\x0e\\x19\\x98)\\xa0\\\\\\xd1\\x0e2\\xd4\\x0e2\\x80G\\xd8\\x04\\x0b\\xd7\\x04\\x1a\\xd2\\x04\\x1a\\x987\\x9c>\\xa87\\xd4+<\\xc8G\\xd0UV\\xc8<\\xd0\\x04\\x1a\\xd1\\x04X\\xd4\\x04X\\xd0\\x04X\\xd0\\x04X\\xd0\\x04X\\x94C\\x00\\x94))t\\x94R\\x94}\\x94(\\x8c\\x0b__package__\\x94\\x8c\\x05lilac\\x94\\x8c\\x08__name__\\x94\\x8c\\x14lilac.router_dataset\\x94\\x8c\\x08__file__\\x94\\x8cg/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lilac/router_dataset.py\\x94uNNNt\\x94R\\x94\\x8c\\x1ccloudpickle.cloudpickle_fast\\x94\\x8c\\x12_function_setstate\\x94\\x93\\x94hK}\\x94}\\x94(hFh=\\x8c\\x0c__qualname__\\x94h>\\x8c\\x0f__annotations__\\x94}\\x94(h5\\x8c\\x08builtins\\x94\\x8c\\x03str\\x94\\x93\\x94h6hVh7hT\\x8c\\x04dict\\x94\\x93\\x94h8hV\\x8c\\x06return\\x94Nu\\x8c\\x0e__kwdefaults__\\x94N\\x8c\\x0c__defaults__\\x94N\\x8c\\n__module__\\x94hG\\x8c\\x07__doc__\\x94N\\x8c\\x0b__closure__\\x94N\\x8c\\x17_cloudpickle_submodules\\x94]\\x94\\x8c\\x0b__globals__\\x94}\\x94(h/hGh/\\x93\\x94h0\\x8c\\x10lilac.db_manager\\x94h0\\x93\\x94uu\\x86\\x94\\x86R0h\\x1e\\x8c\\x08TaskInfo\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x08__dict__\\x94}\\x94(\\x8c\\x04name\\x94\\x8cE[local/chat-langchain_EDA_dataset] Compute signal \"openai\" on \"input\"\\x94\\x8c\\x04type\\x94N\\x8c\\x06status\\x94\\x8c\\x08builtins\\x94\\x8c\\x07getattr\\x94\\x93\\x94h\\x1e\\x8c\\nTaskStatus\\x94\\x93\\x94\\x8c\\x07PENDING\\x94\\x86\\x94R\\x94\\x8c\\x08progress\\x94N\\x8c\\x07message\\x94N\\x8c\\x07details\\x94N\\x8c\\rstep_progress\\x94N\\x8c\\x05steps\\x94N\\x8c\\x0bdescription\\x94\\x8c\\x13Config:  OpenAI({})\\x94\\x8c\\x0fstart_timestamp\\x94\\x8c\\x1a2023-09-08T13:12:51.452925\\x94\\x8c\\rend_timestamp\\x94N\\x8c\\x05error\\x94Nu\\x8c\\x0e__fields_set__\\x94\\x8f\\x94(hyh\\x80hohmh~hp\\x90\\x8c\\x1c__private_attribute_values__\\x94}\\x94ubh\\x1a\\x87\\x94}\\x94Nt\\x94b\\x8c\\x05local\\x94\\x8c\\x1achat-langchain_EDA_dataset\\x94}\\x94(h2}\\x94\\x8c\\x0bsignal_name\\x94\\x8c\\x06openai\\x94sh3\\x8c\\x05input\\x94\\x85\\x94uh\\x1at\\x94subsubsb.'], 'keys': ['90bf7d86052b4978916f0181302a7fec'], 'internal_priority': {'90bf7d86052b4978916f0181302a7fec': 0}, 'submitting_task': None, 'fifo_timeout': '100 ms', 'actors': False, 'code': <ToPickle: ()>, 'annotations': <ToPickle: {}>}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lilac/router_utils.py\", line 24, in custom_route_handler\n",
      "    return await original_route_handler(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fastapi/routing.py\", line 241, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fastapi/routing.py\", line 169, in run_endpoint_function\n",
      "    return await run_in_threadpool(dependant.call, **values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/starlette/concurrency.py\", line 41, in run_in_threadpool\n",
      "    return await anyio.to_thread.run_sync(func, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lilac/router_dataset.py\", line 109, in compute_signal\n",
      "    get_task_manager().execute(task_id, _task_compute_signal, namespace, dataset_name, options.dict(),\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lilac/tasks.py\", line 211, in execute\n",
      "    task_future = self._dask_client.submit(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/distributed/client.py\", line 1970, in submit\n",
      "    futures = self._graph_to_futures(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/distributed/client.py\", line 3157, in _graph_to_futures\n",
      "    self._send_to_scheduler(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/distributed/client.py\", line 1240, in _send_to_scheduler\n",
      "    raise Exception(\n",
      "Exception: Tried sending message after closing.  Status: closed\n",
      "Message: {'op': 'update-graph', 'graph_header': {'serializer': 'pickle', 'writeable': ()}, 'graph_frames': [b'\\x80\\x05\\x95\\x0b\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x1edistributed.protocol.serialize\\x94\\x8c\\x08ToPickle\\x94\\x93\\x94)\\x81\\x94}\\x94\\x8c\\x04data\\x94\\x8c\\x13dask.highlevelgraph\\x94\\x8c\\x0eHighLevelGraph\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x0cdependencies\\x94}\\x94\\x8a\\x05@\\x1d\\x12\\xd1\\x02\\x8f\\x94s\\x8c\\x10key_dependencies\\x94}\\x94\\x8c\\x06layers\\x94}\\x94\\x8a\\x05@\\x1d\\x12\\xd1\\x02h\\x06\\x8c\\x11MaterializedLayer\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x0bannotations\\x94N\\x8c\\x16collection_annotations\\x94N\\x8c\\x07mapping\\x94}\\x94\\x8c 90bf7d86052b4978916f0181302a7fec\\x94(\\x8c\\tfunctools\\x94\\x8c\\x07partial\\x94\\x93\\x94\\x8c\\x0blilac.tasks\\x94\\x8c\\r_execute_task\\x94\\x93\\x94\\x85\\x94R\\x94(h \\x8c\\x17cloudpickle.cloudpickle\\x94\\x8c\\x0e_make_function\\x94\\x93\\x94(h#\\x8c\\r_builtin_type\\x94\\x93\\x94\\x8c\\x08CodeType\\x94\\x85\\x94R\\x94(K\\x04K\\x00K\\x00K\\x06K\\x06K\\x13C\\x86\\x97\\x00t\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x03i\\x00|\\x02\\xa4\\x01\\x8e\\x01}\\x04t\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x00|\\x01\\xa6\\x02\\x00\\x00\\xab\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x05|\\x05\\xa0\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x04j\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x04j\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x03d\\x01f\\x02\\xac\\x02\\xa6\\x03\\x00\\x00\\xab\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00d\\x00S\\x00\\x94(NK\\x00\\x8c\\x0ctask_step_id\\x94\\x85\\x94)t\\x94(\\x8c\\x14ComputeSignalOptions\\x94\\x8c\\x0bget_dataset\\x94\\x8c\\x0ecompute_signal\\x94\\x8c\\x06signal\\x94\\x8c\\tleaf_path\\x94t\\x94(\\x8c\\tnamespace\\x94\\x8c\\x0cdataset_name\\x94\\x8c\\x0coptions_dict\\x94\\x8c\\x07task_id\\x94\\x8c\\x07options\\x94\\x8c\\x07dataset\\x94t\\x94\\x8cg/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lilac/router_dataset.py\\x94\\x8c\\x14_task_compute_signal\\x94\\x8c,compute_signal.<locals>._task_compute_signal\\x94KaCQ\\x80\\x00\\xf5\\x08\\x00\\x0f#\\xd0\\x0e2\\xd0\\x0e2\\xa0\\\\\\xd0\\x0e2\\xd0\\x0e2\\x80G\\xdd\\x0e\\x19\\x98)\\xa0\\\\\\xd1\\x0e2\\xd4\\x0e2\\x80G\\xd8\\x04\\x0b\\xd7\\x04\\x1a\\xd2\\x04\\x1a\\x987\\x9c>\\xa87\\xd4+<\\xc8G\\xd0UV\\xc8<\\xd0\\x04\\x1a\\xd1\\x04X\\xd4\\x04X\\xd0\\x04X\\xd0\\x04X\\xd0\\x04X\\x94C\\x00\\x94))t\\x94R\\x94}\\x94(\\x8c\\x0b__package__\\x94\\x8c\\x05lilac\\x94\\x8c\\x08__name__\\x94\\x8c\\x14lilac.router_dataset\\x94\\x8c\\x08__file__\\x94\\x8cg/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lilac/router_dataset.py\\x94uNNNt\\x94R\\x94\\x8c\\x1ccloudpickle.cloudpickle_fast\\x94\\x8c\\x12_function_setstate\\x94\\x93\\x94hK}\\x94}\\x94(hFh=\\x8c\\x0c__qualname__\\x94h>\\x8c\\x0f__annotations__\\x94}\\x94(h5\\x8c\\x08builtins\\x94\\x8c\\x03str\\x94\\x93\\x94h6hVh7hT\\x8c\\x04dict\\x94\\x93\\x94h8hV\\x8c\\x06return\\x94Nu\\x8c\\x0e__kwdefaults__\\x94N\\x8c\\x0c__defaults__\\x94N\\x8c\\n__module__\\x94hG\\x8c\\x07__doc__\\x94N\\x8c\\x0b__closure__\\x94N\\x8c\\x17_cloudpickle_submodules\\x94]\\x94\\x8c\\x0b__globals__\\x94}\\x94(h/hGh/\\x93\\x94h0\\x8c\\x10lilac.db_manager\\x94h0\\x93\\x94uu\\x86\\x94\\x86R0h\\x1e\\x8c\\x08TaskInfo\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x08__dict__\\x94}\\x94(\\x8c\\x04name\\x94\\x8cE[local/chat-langchain_EDA_dataset] Compute signal \"openai\" on \"input\"\\x94\\x8c\\x04type\\x94N\\x8c\\x06status\\x94\\x8c\\x08builtins\\x94\\x8c\\x07getattr\\x94\\x93\\x94h\\x1e\\x8c\\nTaskStatus\\x94\\x93\\x94\\x8c\\x07PENDING\\x94\\x86\\x94R\\x94\\x8c\\x08progress\\x94N\\x8c\\x07message\\x94N\\x8c\\x07details\\x94N\\x8c\\rstep_progress\\x94N\\x8c\\x05steps\\x94N\\x8c\\x0bdescription\\x94\\x8c\\x13Config:  OpenAI({})\\x94\\x8c\\x0fstart_timestamp\\x94\\x8c\\x1a2023-09-08T13:12:51.452925\\x94\\x8c\\rend_timestamp\\x94N\\x8c\\x05error\\x94Nu\\x8c\\x0e__fields_set__\\x94\\x8f\\x94(hyh\\x80hohmh~hp\\x90\\x8c\\x1c__private_attribute_values__\\x94}\\x94ubh\\x1a\\x87\\x94}\\x94Nt\\x94b\\x8c\\x05local\\x94\\x8c\\x1achat-langchain_EDA_dataset\\x94}\\x94(h2}\\x94\\x8c\\x0bsignal_name\\x94\\x8c\\x06openai\\x94sh3\\x8c\\x05input\\x94\\x85\\x94uh\\x1at\\x94subsubsb.'], 'keys': ['90bf7d86052b4978916f0181302a7fec'], 'internal_priority': {'90bf7d86052b4978916f0181302a7fec': 0}, 'submitting_task': None, 'fifo_timeout': '100 ms', 'actors': False, 'code': <ToPickle: ()>, 'annotations': <ToPickle: {}>}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ll.start_server(project_path='data')\n",
    "await ll.stop_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:5432/datasets'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Navigate to the dataset. It should be visible at\n",
    "\"http://127.0.0.1:5432/datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Dataset Schema\n",
    "\n",
    "The Lil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataset schema\n",
    "dataset.manifest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enriching an unstructured field with metadata\n",
    "\n",
    "Lilac exposes a number of built-in methods to to add structured metadata to your dataset.\n",
    "Called \"signals\", these methods compute a function on each row and add the results as new fields\n",
    "to the field on which they were applied.\n",
    "\n",
    "In this example, we will run a \"signal\" over the `question` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.compute_signal(ll.LangDetectionSignal(), 'question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply min-hash LSH (https://en.wikipedia.org/wiki/MinHash) to detect approximate n-gram duplicates\n",
    "dataset.compute_signal(ll.NearDuplicateSignal(), 'question')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the Dataset\n",
    "\n",
    "Now that we've enriched the dataset, we can query it to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = dataset.select_rows(['question', 'answer'], limit=5)\n",
    "r.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute embedding to enable advanced search\n",
    "\n",
    "Let's compute the `SBERT` embedding on device for the `overview` field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.compute_embedding('sbert', 'question')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ll.KeywordQuery(search='runnable')\n",
    "r = dataset.select_rows(['question'], searches=[ll.Search(path='question', query=query)], limit=5)\n",
    "display(r.df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ll.SemanticQuery(search='runnable', embedding='sbert')\n",
    "r = dataset.select_rows(['overview'], searches=[ll.Search(path='overview', query=query)], limit=5)\n",
    "display(r.df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceptual search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ll.ConceptQuery(concept_namespace='lilac', concept_name='profanity', embedding='sbert')\n",
    "r = dataset.select_rows(['overview'], searches=[ll.Search(path='overview', query=query)], limit=5)\n",
    "display(r.df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the enriched dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('the_movies_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_pandas()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the positive-sentiment concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = ll.signals.ConceptSignal(\n",
    "  namespace='lilac', concept_name='positive-sentiment', embedding='gte-small')\n",
    "\n",
    "result = list(signal.compute(['This product is amazing, thank you!']))\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a positive product reviews concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ll.DiskConceptDB()\n",
    "\n",
    "concepts = db.list()\n",
    "# Don't create the concept twice.\n",
    "if not list(\n",
    "    filter(lambda c: c.namespace == 'local' and c.name == 'positive-product-reviews', concepts)):\n",
    "  db.create('local', 'positive-product-reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a few training examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "  ll.ExampleIn(label=False, text='The quick brown fox jumps over the lazy dog.'),\n",
    "  ll.ExampleIn(label=False, text='This is a random sentence.'),\n",
    "  ll.ExampleIn(label=True, text='This product is amazing!'),\n",
    "  ll.ExampleIn(label=True, text='Thank you for your awesome work on this UI.')\n",
    "]\n",
    "db.edit('local', 'positive-product-reviews', ll.ConceptUpdate(insert=train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the examples in the concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = db.get('local', 'positive-product-reviews')\n",
    "\n",
    "if concept:\n",
    "  print(concept.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.edit('local', 'positive-product-reviews',\n",
    "        ll.ConceptUpdate(remove=['d86e4cb53c70443b8d8782a6847f4752']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use the new concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = ll.signals.ConceptSignal(\n",
    "  namespace='local', concept_name='positive-product-reviews', embedding='gte-small')\n",
    "\n",
    "result = list(signal.compute(['This product is amazing, thank you!']))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concept metrics\n",
    "\n",
    "To compute metrics for a concept, we first have to instantiate a concept model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_db = ll.DiskConceptModelDB(ll.DiskConceptDB())\n",
    "\n",
    "model = model_db.get('local', 'positive-product-reviews', embedding_name='gte-small')\n",
    "\n",
    "if model:\n",
    "  print(model.get_metrics())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.remove('local', 'positive-product-reviews')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
