{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analyze LangSmith Datasets with Lilac\n",
    "\n",
    "Lilac is an open-source product that helps you analyze, structure, and clean unstructured data with AI. \n",
    "\n",
    "Basic overview:\n",
    "- Create dataset from runs\n",
    "- Visualize the data\n",
    "- Query the dataset\n",
    "- Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -U \"lilac[pii]\" langdetect sentence-transformers langsmith --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create dataset of runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We'll start by fetching the root traces from a project\n",
    "from langsmith import Client\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "client = Client()\n",
    "\n",
    "project_name = \"chat-langchain\"\n",
    "start_time = datetime.now() - timedelta(days=7)\n",
    "runs = list(client.list_runs(\n",
    "    project_name=project_name,\n",
    "    start_time=datetime(2021, 1, 1),\n",
    "    execution_order=1,\n",
    "    run_type=\"chain\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from itertools import repeat\n",
    "\n",
    "dataset_name = f\"{project_name}-EDA-2\"\n",
    "# client.delete_dataset(dataset_name=dataset_name)\n",
    "# dataset = client.create_dataset(\n",
    "#     dataset_name=dataset_name,\n",
    "# )\n",
    "\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     executor.map(\n",
    "#         lambda run: client.create_example(\n",
    "#             inputs={\n",
    "#                 **{k: str(v) for k, v in run.inputs.items()},\n",
    "#                 \"run_name\": run.name,\n",
    "#                 \"latency\": (run.end_time - run.start_time).total_seconds(),\n",
    "#             },\n",
    "#             outputs={\n",
    "#                 **{k: str(v) for k, v in (run.outputs or {}).items()},\n",
    "#                 \"error\": str(run.error)\n",
    "#             },\n",
    "#             dataset_id=dataset.id,\n",
    "#         ), \n",
    "#         runs\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From LangSmith Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import lilac as ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from source langsmith...: 100%|██████████████████████████████████| 3330/3330 [00:00<00:00, 133136.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"chat-langchain-EDA-2\" written to ./data/datasets/local/chat-langchain-EDA-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_source = ll.sources.langsmith.LangSmithSource(\n",
    "    dataset_name=dataset_name,\n",
    ")\n",
    "\n",
    "config = ll.DatasetConfig(\n",
    "  namespace='local',\n",
    "  name=dataset_name,\n",
    "  source=data_source,\n",
    ")\n",
    "\n",
    "dataset = ll.create_dataset(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "Now that we have imported a few datasets, let's visualize them to see what they look like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [62357]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:5432 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling task \"8f866626bf1c4a169224a47feb2a12c2\": \"[local/langsmith-eda] Load dataset\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[local/langsmith-eda] Load dataset: 100%|█████████████████████████████████████████| 4/4 [00:00<00:00, 522.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"langsmith-eda\" written to ./datasets/local/langsmith-eda\n",
      "Task completed \"8f866626bf1c4a169224a47feb2a12c2\": \"[local/langsmith-eda] Load dataset\" in 0s.\n"
     ]
    }
   ],
   "source": [
    "ll.start_server()\n",
    "# await ll.stop_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Navigate to the dataset. It should be visible at\n",
    "\"http://127.0.0.1:5432/datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Dataset Schema\n",
    "\n",
    "The Lil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataset schema\n",
    "dataset.manifest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enriching an unstructured field with metadata\n",
    "\n",
    "Lilac exposes a number of built-in methods to to add structured metadata to your dataset.\n",
    "Called \"signals\", these methods compute a function on each row and add the results as new fields\n",
    "to the field on which they were applied.\n",
    "\n",
    "In this example, we will run a \"signal\" over the `question` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.compute_signal(ll.LangDetectionSignal(), 'question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply min-hash LSH (https://en.wikipedia.org/wiki/MinHash) to detect approximate n-gram duplicates\n",
    "dataset.compute_signal(ll.NearDuplicateSignal(), 'question')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the Dataset\n",
    "\n",
    "Now that we've enriched the dataset, we can query it to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = dataset.select_rows(['question', 'answer'], limit=5)\n",
    "r.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute embedding to enable advanced search\n",
    "\n",
    "Let's compute the `SBERT` embedding on device for the `overview` field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.compute_embedding('sbert', 'question')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ll.KeywordQuery(search='runnable')\n",
    "r = dataset.select_rows(['question'], searches=[ll.Search(path='question', query=query)], limit=5)\n",
    "display(r.df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ll.SemanticQuery(search='runnable', embedding='sbert')\n",
    "r = dataset.select_rows(['overview'], searches=[ll.Search(path='overview', query=query)], limit=5)\n",
    "display(r.df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceptual search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ll.ConceptQuery(concept_namespace='lilac', concept_name='profanity', embedding='sbert')\n",
    "r = dataset.select_rows(['overview'], searches=[ll.Search(path='overview', query=query)], limit=5)\n",
    "display(r.df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the enriched dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('the_movies_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_pandas()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the positive-sentiment concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = ll.signals.ConceptSignal(\n",
    "  namespace='lilac', concept_name='positive-sentiment', embedding='gte-small')\n",
    "\n",
    "result = list(signal.compute(['This product is amazing, thank you!']))\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a positive product reviews concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ll.DiskConceptDB()\n",
    "\n",
    "concepts = db.list()\n",
    "# Don't create the concept twice.\n",
    "if not list(\n",
    "    filter(lambda c: c.namespace == 'local' and c.name == 'positive-product-reviews', concepts)):\n",
    "  db.create('local', 'positive-product-reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a few training examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "  ll.ExampleIn(label=False, text='The quick brown fox jumps over the lazy dog.'),\n",
    "  ll.ExampleIn(label=False, text='This is a random sentence.'),\n",
    "  ll.ExampleIn(label=True, text='This product is amazing!'),\n",
    "  ll.ExampleIn(label=True, text='Thank you for your awesome work on this UI.')\n",
    "]\n",
    "db.edit('local', 'positive-product-reviews', ll.ConceptUpdate(insert=train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the examples in the concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = db.get('local', 'positive-product-reviews')\n",
    "\n",
    "if concept:\n",
    "  print(concept.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.edit('local', 'positive-product-reviews',\n",
    "        ll.ConceptUpdate(remove=['d86e4cb53c70443b8d8782a6847f4752']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use the new concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = ll.signals.ConceptSignal(\n",
    "  namespace='local', concept_name='positive-product-reviews', embedding='gte-small')\n",
    "\n",
    "result = list(signal.compute(['This product is amazing, thank you!']))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concept metrics\n",
    "\n",
    "To compute metrics for a concept, we first have to instantiate a concept model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_db = ll.DiskConceptModelDB(ll.DiskConceptDB())\n",
    "\n",
    "model = model_db.get('local', 'positive-product-reviews', embedding_name='gte-small')\n",
    "\n",
    "if model:\n",
    "  print(model.get_metrics())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.remove('local', 'positive-product-reviews')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
