{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze LangSmith Datasets with Lilac\n",
    "\n",
    "Lilac is an open-source product that helps you analyze, structure, and clean unstructured data with AI. Let's use it to explore production traces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U \"lilac[pii]\" langdetect sentence-transformers langsmith --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From LangSmith\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import lilac as ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from source langsmith...: 100%|███████████████████████████████████████| 46/46 [00:00<00:00, 11020.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"langsmith\" written to ./datasets/local/langsmith\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'Chat LangChain Questions'\n",
    "data_source = ll.sources.langsmith.LangSmithSource(dataset_name=dataset_name)\n",
    "\n",
    "config = ll.DatasetConfig(\n",
    "  namespace='local',\n",
    "  name='langsmith',\n",
    "  source=data_source,\n",
    ")\n",
    "dataset = ll.create_dataset(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "Now that we have imported a few datasets, let's visualize them to see what they look like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ll.start_server()\n",
    "# await ll.stop_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:5432/datasets#local/langsmith'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"http://127.0.0.1:5432/datasets#local/langsmith\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Dataset Schema\n",
    "\n",
    "The Lil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetManifest(namespace='local', dataset_name='langsmith', data_schema={\n",
       "  \"fields\": {\n",
       "    \"question\": {\n",
       "      \"dtype\": \"string\"\n",
       "    },\n",
       "    \"answer\": {\n",
       "      \"dtype\": \"string\"\n",
       "    }\n",
       "  }\n",
       "}, source=LangSmithSource(dataset_name='Chat LangChain Questions'), num_items=46)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the dataset schema\n",
    "dataset.manifest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enriching an unstructured field with metadata\n",
    "\n",
    "Lilac exposes a number of built-in methods to to add structured metadata to your dataset.\n",
    "Called \"signals\", these methods compute a function on each row and add the results as new fields\n",
    "to the field on which they were applied.\n",
    "\n",
    "In this example, we will run a \"signal\" over the `question` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing lang_detection on local/langsmith:('question',): 100%|█████████████████| 46/46 [00:00<00:00, 46.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing signal \"lang_detection\" on local/langsmith:('question',) took 1.062s.\n",
      "Wrote signal output to ./datasets/local/langsmith/question/lang_detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.compute_signal(ll.LangDetectionSignal(), 'question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing near_dup on local/langsmith:('question',):   0%|                                | 0/46 [00:00<?, ?it/s]\n",
      "Fingerprinting...: 46it [00:00, 6597.97it/s]\n",
      "\n",
      "Computing hash collisions...: 100%|██████████████████████████████████████████████| 1/1 [00:00<00:00, 1426.63it/s]\u001b[A\n",
      "\n",
      "Clustering...: 100%|█████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 149386.17it/s]\u001b[A\n",
      "Computing near_dup on local/langsmith:('question',): 100%|██████████████████████| 46/46 [00:00<00:00, 984.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing signal \"near_dup\" on local/langsmith:('question',) took 0.051s.\n",
      "Wrote signal output to ./datasets/local/langsmith/question/near_dup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply min-hash LSH (https://en.wikipedia.org/wiki/MinHash) to detect approximate n-gram duplicates\n",
    "dataset.compute_signal(ll.NearDuplicateSignal(), 'question')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the Dataset\n",
    "\n",
    "Now that we've enriched the dataset, we can query it to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I create a simple chat model using my ...</td>\n",
       "      <td>Certainly! To create a simple chat model using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can you show a me an example of how to create ...</td>\n",
       "      <td>Certainly! To create a vector store with Azure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Help me debug: TypeError: Pinecone.similarity_...</td>\n",
       "      <td>Your error is likely due to an incorrect param...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whats the code to load text file into a vector...</td>\n",
       "      <td>To load a text file into a vector store using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is RAG</td>\n",
       "      <td>RAG stands for Retrieval Augmented Generation....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How can I create a simple chat model using my ...   \n",
       "1  Can you show a me an example of how to create ...   \n",
       "2  Help me debug: TypeError: Pinecone.similarity_...   \n",
       "3  whats the code to load text file into a vector...   \n",
       "4                                        what is RAG   \n",
       "\n",
       "                                              answer  \n",
       "0  Certainly! To create a simple chat model using...  \n",
       "1  Certainly! To create a vector store with Azure...  \n",
       "2  Your error is likely due to an incorrect param...  \n",
       "3  To load a text file into a vector store using ...  \n",
       "4  RAG stands for Retrieval Augmented Generation....  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = dataset.select_rows(['question', 'answer'], limit=5)\n",
    "r.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute embedding to enable advanced search\n",
    "\n",
    "Let's compute the `SBERT` embedding on device for the `overview` field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing sbert on local/langsmith:('question',): 100%|██████████████████████████| 46/46 [00:05<00:00,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing signal \"sbert\" on local/langsmith:('question',) took 5.961s.\n",
      "hnswlib index creation took 0.004s.\n",
      "Wrote embedding index to ./datasets/local/langsmith/question/sbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.compute_embedding('sbert', 'question')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'lilac' has no attribute 'KeywordQuery'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[43mll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKeywordQuery\u001b[49m(search\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrunnable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m r \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mselect_rows([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m], searches\u001b[38;5;241m=\u001b[39m[ll\u001b[38;5;241m.\u001b[39mSearch(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m, query\u001b[38;5;241m=\u001b[39mquery)], limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      3\u001b[0m display(r\u001b[38;5;241m.\u001b[39mdf())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'lilac' has no attribute 'KeywordQuery'"
     ]
    }
   ],
   "source": [
    "query = ll.KeywordQuery(search='runnable')\n",
    "r = dataset.select_rows(['question'], searches=[ll.Search(path='question', query=query)], limit=5)\n",
    "display(r.df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'lilac' has no attribute 'SemanticQuery'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[43mll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSemanticQuery\u001b[49m(search\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrunnable\u001b[39m\u001b[38;5;124m'\u001b[39m, embedding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msbert\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m r \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mselect_rows([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m'\u001b[39m], searches\u001b[38;5;241m=\u001b[39m[ll\u001b[38;5;241m.\u001b[39mSearch(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m'\u001b[39m, query\u001b[38;5;241m=\u001b[39mquery)], limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      3\u001b[0m display(r\u001b[38;5;241m.\u001b[39mdf())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'lilac' has no attribute 'SemanticQuery'"
     ]
    }
   ],
   "source": [
    "query = ll.SemanticQuery(search='runnable', embedding='sbert')\n",
    "r = dataset.select_rows(['overview'], searches=[ll.Search(path='overview', query=query)], limit=5)\n",
    "display(r.df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceptual search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[43mll\u001b[49m\u001b[38;5;241m.\u001b[39mConceptQuery(concept_namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlilac\u001b[39m\u001b[38;5;124m'\u001b[39m, concept_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofanity\u001b[39m\u001b[38;5;124m'\u001b[39m, embedding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msbert\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m r \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mselect_rows([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m'\u001b[39m], searches\u001b[38;5;241m=\u001b[39m[ll\u001b[38;5;241m.\u001b[39mSearch(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m'\u001b[39m, query\u001b[38;5;241m=\u001b[39mquery)], limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      3\u001b[0m display(r\u001b[38;5;241m.\u001b[39mdf())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'll' is not defined"
     ]
    }
   ],
   "source": [
    "query = ll.ConceptQuery(concept_namespace='lilac', concept_name='profanity', embedding='sbert')\n",
    "r = dataset.select_rows(['overview'], searches=[ll.Search(path='overview', query=query)], limit=5)\n",
    "display(r.df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the enriched dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('the_movies_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_pandas()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the positive-sentiment concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = ll.signals.ConceptSignal(\n",
    "  namespace='lilac', concept_name='positive-sentiment', embedding='gte-small')\n",
    "\n",
    "result = list(signal.compute(['This product is amazing, thank you!']))\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a positive product reviews concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ll.DiskConceptDB()\n",
    "\n",
    "concepts = db.list()\n",
    "# Don't create the concept twice.\n",
    "if not list(\n",
    "    filter(lambda c: c.namespace == 'local' and c.name == 'positive-product-reviews', concepts)):\n",
    "  db.create('local', 'positive-product-reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a few training examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "  ll.ExampleIn(label=False, text='The quick brown fox jumps over the lazy dog.'),\n",
    "  ll.ExampleIn(label=False, text='This is a random sentence.'),\n",
    "  ll.ExampleIn(label=True, text='This product is amazing!'),\n",
    "  ll.ExampleIn(label=True, text='Thank you for your awesome work on this UI.')\n",
    "]\n",
    "db.edit('local', 'positive-product-reviews', ll.ConceptUpdate(insert=train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the examples in the concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = db.get('local', 'positive-product-reviews')\n",
    "\n",
    "if concept:\n",
    "  print(concept.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.edit('local', 'positive-product-reviews',\n",
    "        ll.ConceptUpdate(remove=['d86e4cb53c70443b8d8782a6847f4752']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use the new concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = ll.signals.ConceptSignal(\n",
    "  namespace='local', concept_name='positive-product-reviews', embedding='gte-small')\n",
    "\n",
    "result = list(signal.compute(['This product is amazing, thank you!']))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concept metrics\n",
    "\n",
    "To compute metrics for a concept, we first have to instantiate a concept model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_db = ll.DiskConceptModelDB(ll.DiskConceptDB())\n",
    "\n",
    "model = model_db.get('local', 'positive-product-reviews', embedding_name='gte-small')\n",
    "\n",
    "if model:\n",
    "  print(model.get_metrics())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.remove('local', 'positive-product-reviews')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
